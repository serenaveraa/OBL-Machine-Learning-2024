{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qS78xdfwTdMl"
   },
   "source": [
    "# Cargar y explorar los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "roBADtGxj4Qk",
    "outputId": "74d8007e-842a-4792-e19c-e28806b4f527"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# If necessary, install required packages (use pip in the terminal)\n",
    "# pip install matplotlib scikit-learn pandas\n",
    "# pip install pandas-profiling\n",
    "\n",
    "# 2. Cargar el dataset\n",
    "df_train = pd.read_csv('./dataset/train.csv')  # Change this to the correct local path\n",
    "df_test = pd.read_csv('./dataset/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:voyxj3h0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2935a3d68ef44073a79b2ea8b2de5ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.007 MB of 0.007 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">DecTree#1</strong> at: <a href='https://wandb.ai/sv267108-universidad-ort-uruguay/OBL-MACHINE-LEARNING-2024/runs/voyxj3h0' target=\"_blank\">https://wandb.ai/sv267108-universidad-ort-uruguay/OBL-MACHINE-LEARNING-2024/runs/voyxj3h0</a><br/> View project at: <a href='https://wandb.ai/sv267108-universidad-ort-uruguay/OBL-MACHINE-LEARNING-2024' target=\"_blank\">https://wandb.ai/sv267108-universidad-ort-uruguay/OBL-MACHINE-LEARNING-2024</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241126_125806-voyxj3h0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:voyxj3h0). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Karina\\OneDrive\\Documents\\GitHub\\OBL-Machine-Learning-2024\\wandb\\run-20241126_130354-oyvdbrft</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sv267108-universidad-ort-uruguay/OBL-MACHINE-LEARNING-2024/runs/oyvdbrft' target=\"_blank\">DecTree#1</a></strong> to <a href='https://wandb.ai/sv267108-universidad-ort-uruguay/OBL-MACHINE-LEARNING-2024' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sv267108-universidad-ort-uruguay/OBL-MACHINE-LEARNING-2024' target=\"_blank\">https://wandb.ai/sv267108-universidad-ort-uruguay/OBL-MACHINE-LEARNING-2024</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sv267108-universidad-ort-uruguay/OBL-MACHINE-LEARNING-2024/runs/oyvdbrft' target=\"_blank\">https://wandb.ai/sv267108-universidad-ort-uruguay/OBL-MACHINE-LEARNING-2024/runs/oyvdbrft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sv267108-universidad-ort-uruguay/OBL-MACHINE-LEARNING-2024/runs/oyvdbrft?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1c68167f610>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log into wandb\n",
    "import wandb\n",
    "wandb.init(\n",
    "    project=\"OBL-MACHINE-LEARNING-2024\",\n",
    "    name=\"DecTree#1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "collapsed": true,
    "id": "opjak8-1tTvR",
    "outputId": "ad330336-4337-43ea-8f33-0cc457cdfae9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11030 entries, 0 to 11029\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 11030 non-null  int64  \n",
      " 1   Game Title         11030 non-null  object \n",
      " 2   Year               11014 non-null  float64\n",
      " 3   Publisher          9992 non-null   object \n",
      " 4   North America      11030 non-null  float64\n",
      " 5   Europe             11030 non-null  float64\n",
      " 6   Japan              11030 non-null  float64\n",
      " 7   Rest of World      11030 non-null  float64\n",
      " 8   Global             11030 non-null  float64\n",
      " 9   Number of Reviews  11030 non-null  object \n",
      " 10  Summary            1098 non-null   object \n",
      " 11  Wishlist           11030 non-null  object \n",
      " 12  Platform           11030 non-null  object \n",
      " 13  Genre              11030 non-null  object \n",
      " 14  Rating             11030 non-null  float64\n",
      "dtypes: float64(7), int64(1), object(7)\n",
      "memory usage: 1.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Game Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>North America</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Japan</th>\n",
       "      <th>Rest of World</th>\n",
       "      <th>Global</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Wishlist</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bloodstained: Curse of the Moon</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>341.0</td>\n",
       "      <td>“Bloodstained: Curse of the Moon” is packed wi...</td>\n",
       "      <td>397.0</td>\n",
       "      <td>2600</td>\n",
       "      <td>Platform</td>\n",
       "      <td>7.345609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Plants vs. Zombies</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>719.0</td>\n",
       "      <td>Zombies are invading your home, and the only d...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2600</td>\n",
       "      <td>Puzzle</td>\n",
       "      <td>6.511195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Zero Escape: Zero Time Dilemma</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Zero Time Dilemma is the third and final entry...</td>\n",
       "      <td>402.0</td>\n",
       "      <td>2600</td>\n",
       "      <td>Puzzle</td>\n",
       "      <td>6.651093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Zelda II: The Adventure of Link</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.38</td>\n",
       "      <td>756.0</td>\n",
       "      <td>Zelda II: The Adventure of Link is the second ...</td>\n",
       "      <td>290.0</td>\n",
       "      <td>NES</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>7.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Yume Nikki</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>770.0</td>\n",
       "      <td>Yume Nikki is a 32-Bit freeware game created b...</td>\n",
       "      <td>771.0</td>\n",
       "      <td>2600</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>7.152074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                       Game Title    Year Publisher  North America  \\\n",
       "0   1  Bloodstained: Curse of the Moon  2007.0       NaN           0.08   \n",
       "1   2               Plants vs. Zombies  2007.0       NaN           0.08   \n",
       "2   3   Zero Escape: Zero Time Dilemma  2007.0       NaN           0.08   \n",
       "3   4  Zelda II: The Adventure of Link  1987.0  Nintendo           2.19   \n",
       "4   5                       Yume Nikki  2007.0       NaN           0.08   \n",
       "\n",
       "   Europe  Japan  Rest of World  Global Number of Reviews  \\\n",
       "0    0.02   0.00           0.01    0.17             341.0   \n",
       "1    0.02   0.00           0.01    0.17             719.0   \n",
       "2    0.02   0.00           0.01    0.17             350.0   \n",
       "3    0.50   1.61           0.08    4.38             756.0   \n",
       "4    0.02   0.00           0.01    0.17             770.0   \n",
       "\n",
       "                                             Summary Wishlist Platform  \\\n",
       "0  “Bloodstained: Curse of the Moon” is packed wi...    397.0     2600   \n",
       "1  Zombies are invading your home, and the only d...     82.0     2600   \n",
       "2  Zero Time Dilemma is the third and final entry...    402.0     2600   \n",
       "3  Zelda II: The Adventure of Link is the second ...    290.0      NES   \n",
       "4  Yume Nikki is a 32-Bit freeware game created b...    771.0     2600   \n",
       "\n",
       "       Genre    Rating  \n",
       "0   Platform  7.345609  \n",
       "1     Puzzle  6.511195  \n",
       "2     Puzzle  6.651093  \n",
       "3  Adventure  7.900000  \n",
       "4  Adventure  7.152074  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resumen de la información del dataframe\n",
    "df_train.info()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "jIv0ENS7tv0g",
    "outputId": "4002009d-c2db-4919-966c-c5c30df58e1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                      0\n",
      "Game Title              0\n",
      "Year                   16\n",
      "Publisher            1038\n",
      "North America           0\n",
      "Europe                  0\n",
      "Japan                   0\n",
      "Rest of World           0\n",
      "Global                  0\n",
      "Number of Reviews       0\n",
      "Summary              9932\n",
      "Wishlist                0\n",
      "Platform                0\n",
      "Genre                   0\n",
      "Rating                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df_train.isnull().sum()\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzf3IFM8T6xk"
   },
   "source": [
    "# Rellenar valores faltantes:\n",
    "En Publisher, rellenamos con una categoría como \"Unknown\" si no es crucial.\n",
    "Para Summary, la eliminamos ya que no es relevante para la clasificación o utilizar técnicas de procesamiento de texto si planeas incluirla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ppNwVeKLUGT-",
    "outputId": "85680cca-0431-4828-e809-0b689fa50e04"
   },
   "outputs": [],
   "source": [
    "# Rellenar valores faltantes\n",
    "def clean_data(df):\n",
    "    # Fill missing 'Year' values with the median of the column\n",
    "    df['Year'] = df['Year'].fillna(df['Year'].median())\n",
    "    \n",
    "    # Fill missing 'Publisher' values with 'Unknown'\n",
    "    df['Publisher'] = df['Publisher'].fillna('Unknown')\n",
    "    \n",
    "    # Drop the 'Summary' column if it exists\n",
    "    if 'Summary' in df.columns:\n",
    "        df = df.drop(columns=['Summary'])\n",
    "    \n",
    "    # Check and return remaining missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    \n",
    "    # Print missing values\n",
    "    print(\"Missing values after cleaning:\")\n",
    "    print(missing_values)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ne8d-BkaV9Ux"
   },
   "source": [
    "# Convertir variables categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwWlyi4HdQT1",
    "outputId": "20e3d15c-8b12-49a8-ce7b-30750a2de84c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def preprocess_data(df, is_train=True):    \n",
    "    # Limpiar los datos\n",
    "    df = clean_data(df)\n",
    "    \n",
    "    # Función auxiliar para convertir cadenas con 'K' a valores numéricos\n",
    "    def convert_to_numeric(value):\n",
    "        value_str = str(value)\n",
    "        if 'K' in value_str:\n",
    "            return int(float(value_str.replace('K', '')) * 1000)\n",
    "        else:\n",
    "            return int(float(value_str))\n",
    "    \n",
    "    # Aplicar la conversión a columnas numéricas\n",
    "    columns_to_convert = [\n",
    "        'Europe', 'Japan', 'Rest of World', 'North America', \n",
    "        'Global', 'Number of Reviews', 'Wishlist'\n",
    "    ]\n",
    "    for column in columns_to_convert:\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].apply(convert_to_numeric)\n",
    "    \n",
    "    # Codificación de variables categóricas\n",
    "    label_encoder = LabelEncoder()\n",
    "    categorical_columns = ['Game Title', 'Publisher', 'Platform', 'Genre']\n",
    "    for column in categorical_columns:\n",
    "        if column in df.columns:\n",
    "            df[column] = label_encoder.fit_transform(df[column])\n",
    "    \n",
    "    # Separar características y objetivo en el conjunto de entrenamiento\n",
    "    if is_train:\n",
    "        # Si es el conjunto de entrenamiento, devolver características y objetivo\n",
    "        X = df.drop(columns=['id', 'Rating'], errors='ignore')\n",
    "        y = df['Rating'] if 'Rating' in df.columns else None\n",
    "        return X, y\n",
    "    else:\n",
    "        # Si es el conjunto de prueba, eliminar 'id' y 'Rating' y devolver solo características\n",
    "        X = df.drop(columns=['id', 'Rating'], errors='ignore')\n",
    "        return X\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# X_train, y_train = preprocess_data(df_train, is_train=True)\n",
    "# X_test = preprocess_data(df_test, is_train=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMsnUfbndir_"
   },
   "source": [
    "# Separar características y objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9s7SqSEQdn-n",
    "outputId": "baa7a064-254e-47ef-906b-93c863774275"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "def find_best_depth_classification(X, Y, test_size=0.33, max_depth=20, cv=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Finds the best max_depth for a DecisionTreeClassifier using cross-validation.\n",
    "    \"\"\"\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state)\n",
    "    depth_range = range(1, max_depth + 1)\n",
    "    mean_scores = []\n",
    "\n",
    "    for depth in depth_range:\n",
    "        model = DecisionTreeClassifier(max_depth=depth, random_state=random_state)\n",
    "        scores = cross_val_score(model, X_train, Y_train, cv=cv, scoring='accuracy')  # Use accuracy for classification\n",
    "        mean_scores.append(np.mean(scores))\n",
    "\n",
    "    best_depth = depth_range[np.argmax(mean_scores)]\n",
    "    best_score = max(mean_scores)\n",
    "\n",
    "    print(f\"Best depth: {best_depth}\")\n",
    "    print(f\"Average Accuracy with cross-validation: {best_score:.4f}\")\n",
    "\n",
    "    return best_depth, best_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GD7PT4cYtAg"
   },
   "source": [
    "# Hacer arbol y evaluarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "collapsed": true,
    "id": "nMdNV58VQWwt",
    "outputId": "cb3eee20-a069-48a8-c877-e9f4e5072c71"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_and_evaluate_decision_tree_classification(X, Y, best_depth, test_size=0.33, random_state=42):\n",
    "    \"\"\"\n",
    "    Train and evaluate the decision tree for classification.\n",
    "    \"\"\"\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state)\n",
    "    model = DecisionTreeClassifier(max_depth=best_depth, random_state=random_state)\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "    recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "    f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "    # Log metrics to wandb\n",
    "    wandb.log({\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"best_depth\": best_depth\n",
    "    })\n",
    "\n",
    "    # Plot decision tree\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    tree.plot_tree(model, filled=True, feature_names=X.columns, class_names=np.unique(Y).astype(str), fontsize=10)\n",
    "    plt.title(f\"Decision Tree (Depth = {best_depth})\")\n",
    "    plt.show()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Correr todas las funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_decision_tree_workflow_classification(df_train, df_test):\n",
    "    \"\"\"\n",
    "    Workflow to preprocess, train, and evaluate a Decision Tree Classifier.\n",
    "    \"\"\"\n",
    "    # Preprocess the data\n",
    "    X_train, Y_train = preprocess_data(df_train, is_train=True)\n",
    "    X_test = preprocess_data(df_test, is_train=False)\n",
    "\n",
    "    # Find the best depth\n",
    "    best_depth, best_score = find_best_depth_classification(X_train, Y_train)\n",
    "\n",
    "    # Train and evaluate the model with the best depth\n",
    "    best_model = train_and_evaluate_decision_tree_classification(X_train, Y_train, best_depth)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluar test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after cleaning:\n",
      "id                   0\n",
      "Game Title           0\n",
      "Year                 0\n",
      "Publisher            0\n",
      "North America        0\n",
      "Europe               0\n",
      "Japan                0\n",
      "Rest of World        0\n",
      "Global               0\n",
      "Number of Reviews    0\n",
      "Wishlist             0\n",
      "Platform             0\n",
      "Genre                0\n",
      "Rating               0\n",
      "dtype: int64\n",
      "Missing values after cleaning:\n",
      "id                   0\n",
      "Game Title           0\n",
      "Year                 0\n",
      "Publisher            0\n",
      "North America        0\n",
      "Europe               0\n",
      "Japan                0\n",
      "Rest of World        0\n",
      "Global               0\n",
      "Number of Reviews    0\n",
      "Wishlist             0\n",
      "Platform             0\n",
      "Genre                0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Karina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Karina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Karina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 1009, in fit\n    super()._fit(\n  File \"C:\\Users\\Karina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 294, in _fit\n    check_classification_targets(y)\n  File \"C:\\Users\\Karina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\multiclass.py\", line 219, in check_classification_targets\n    raise ValueError(\nValueError: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Run the workflow\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m workflow_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_decision_tree_workflow_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Get predictions for the test set\u001b[39;00m\n\u001b[0;32m     15\u001b[0m best_model \u001b[38;5;241m=\u001b[39m workflow_results\n",
      "Cell \u001b[1;32mIn[30], line 10\u001b[0m, in \u001b[0;36mrun_decision_tree_workflow_classification\u001b[1;34m(df_train, df_test)\u001b[0m\n\u001b[0;32m      7\u001b[0m X_test \u001b[38;5;241m=\u001b[39m preprocess_data(df_test, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Find the best depth\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m best_depth, best_score \u001b[38;5;241m=\u001b[39m \u001b[43mfind_best_depth_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Train and evaluate the model with the best depth\u001b[39;00m\n\u001b[0;32m     13\u001b[0m best_model \u001b[38;5;241m=\u001b[39m train_and_evaluate_decision_tree_classification(X_train, Y_train, best_depth)\n",
      "Cell \u001b[1;32mIn[28], line 15\u001b[0m, in \u001b[0;36mfind_best_depth_classification\u001b[1;34m(X, Y, test_size, max_depth, cv, random_state)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m depth \u001b[38;5;129;01min\u001b[39;00m depth_range:\n\u001b[0;32m     14\u001b[0m     model \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(max_depth\u001b[38;5;241m=\u001b[39mdepth, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m---> 15\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use accuracy for classification\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     mean_scores\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(scores))\n\u001b[0;32m     18\u001b[0m best_depth \u001b[38;5;241m=\u001b[39m depth_range[np\u001b[38;5;241m.\u001b[39margmax(mean_scores)]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:443\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    425\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    441\u001b[0m )\n\u001b[1;32m--> 443\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Karina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Karina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Karina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 1009, in fit\n    super()._fit(\n  File \"C:\\Users\\Karina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py\", line 294, in _fit\n    check_classification_targets(y)\n  File \"C:\\Users\\Karina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\multiclass.py\", line 219, in check_classification_targets\n    raise ValueError(\nValueError: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.\n"
     ]
    }
   ],
   "source": [
    "def run_model_on_test_classification(best_model, df_test):\n",
    "    \"\"\"\n",
    "    Run predictions on the test dataset with the trained model.\n",
    "    \"\"\"\n",
    "    X_test = preprocess_data(df_test, is_train=False)\n",
    "    predictions = best_model.predict(X_test)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Run the workflow\n",
    "workflow_results = run_decision_tree_workflow_classification(df_train, df_test)\n",
    "\n",
    "# Get predictions for the test set\n",
    "best_model = workflow_results\n",
    "df_results = run_model_on_test_classification(best_model, df_test)\n",
    "\n",
    "# Save submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': df_test['id'],  # Ensure the test dataset contains an 'id' column\n",
    "    'Prediction': df_results\n",
    "})\n",
    "\n",
    "submission.to_csv('submission#2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzfARi68v9c8"
   },
   "outputs": [],
   "source": [
    "# Crear un DataFrame para las predicciones\n",
    "\n",
    "#evaluar nuestro modelo con test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTT8i9DnyyY0"
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(best_model, 'tree.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(best_model, 'tree.joblib')\n",
    "\n",
    "#model.load('tree.joblib')\n",
    "#model.predict(X_test)\n",
    " #  Guardar el modelo en un archivo"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
