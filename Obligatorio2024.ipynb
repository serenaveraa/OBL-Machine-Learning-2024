{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obligatorio - Machine Learning\n",
    "\n",
    "# 1. Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones principales\n",
    "import pandas as pd  # Manejo y análisis de datos estructurados (DataFrames)\n",
    "import numpy as np  # Operaciones numéricas y manejo de arrays\n",
    "import matplotlib.pyplot as plt  # Visualización de datos\n",
    "\n",
    "# Preprocesamiento y selección de características\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  # Codificación de variables categóricas y escalado de datos\n",
    "from sklearn.feature_selection import f_regression, SelectKBest  # Selección de características relevantes basadas en correlación\n",
    "\n",
    "# Modelos de aprendizaje supervisado\n",
    "from sklearn.linear_model import LinearRegression, Ridge  # Modelos lineales para regresión (Ridge incluye regularización)\n",
    "from sklearn.tree import DecisionTreeRegressor  # Árboles de decisión para regresión\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor  # Modelos avanzados: Random Forest, Gradient Boosting, AdaBoost\n",
    "from sklearn.neural_network import MLPRegressor  # Redes neuronales para regresión\n",
    "\n",
    "# Evaluación y optimización\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score  # Dividir datos, búsqueda de hiperparámetros y validación cruzada\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # Métricas de evaluación para modelos de regresión\n",
    "\n",
    "# Text Mining\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Representación numérica de texto (TF-IDF)\n",
    "\n",
    "# Utilidades estadísticas y preprocesamiento avanzado\n",
    "from scipy.stats.mstats import winsorize  # Manejo de valores extremos (outliers) mediante winsorización\n",
    "\n",
    "# Herramientas de pipeline\n",
    "from sklearn.pipeline import Pipeline  # Construcción de pipelines para flujos de preprocesamiento y modelado\n",
    "\n",
    "# Visualización adicional\n",
    "import matplotlib.pyplot as plt  # Gráficos adicionales para análisis visual\n",
    "\n",
    "# Weights and Biases\n",
    "import wandb  # Seguimiento, visualización y registro de métricas para experimentos de Machine Learning\n",
    "\n",
    "import os\n",
    "from math import sqrt\n",
    "\n",
    "# Cargar datasets\n",
    "df_train = pd.read_csv('./dataset/train.csv')  # Cargar el conjunto de entrenamiento\n",
    "df_test = pd.read_csv('./dataset/test.csv')  # Cargar el conjunto de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Rellenar valores faltantes\n",
    "def clean_data(df):\n",
    "    # Completar valores faltantes\n",
    "    df['Year'] = df['Year'].fillna(df['Year'].median())  # Completar con la mediana\n",
    "    df['Publisher'] = df['Publisher'].fillna('Unknown')  # Completar con \"Unknown\"\n",
    "\n",
    "    # Eliminar columnas irrelevantes\n",
    "    if 'Summary' in df.columns:\n",
    "        df = df.drop(columns=['Summary'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Paso 2: Convertir columnas numéricas con valores inconsistentes\n",
    "def convert_to_numeric(value):\n",
    "    \"\"\"\n",
    "    Convierte valores como '1.2K' en valores numéricos.\n",
    "    \"\"\"\n",
    "    value_str = str(value)\n",
    "    if 'K' in value_str:\n",
    "        return float(value_str.replace('K', '')) * 1000\n",
    "    try:\n",
    "        return float(value_str)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "# Paso 3: Manejar outliers\n",
    "def handle_outliers(df, columns):\n",
    "    \"\"\"\n",
    "    Aplica winsorización para manejar valores extremos en las columnas especificadas.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = winsorize(df[col], limits=[0.01, 0.01])  # Recorta 1% inferior y superior\n",
    "    return df\n",
    "\n",
    "# Paso 4: Codificar variables categóricas\n",
    "def encode_categorical(df, categorical_columns):\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in categorical_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = label_encoder.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "# Paso 5: Escalar columnas numéricas\n",
    "def scale_numerical(df, numerical_columns):\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "    return df\n",
    "\n",
    "# Paso 6: Rellenar valores faltantes en `Genre` usando `Summary`\n",
    "def fill_missing_genres(df):\n",
    "    \"\"\"\n",
    "    Rellena los valores faltantes de la columna `Genre` basándose en la columna `Summary`.\n",
    "    Utiliza un modelo de clasificación de texto.\n",
    "    \"\"\"\n",
    "    # Separar filas con y sin `Genre`\n",
    "    df_with_genre = df[df['Genre'].notnull()]\n",
    "    df_missing_genre = df[df['Genre'].isnull()]\n",
    "\n",
    "    if len(df_missing_genre) > 0:\n",
    "        # Convertir valores categóricos de `Genre` a números\n",
    "        label_encoder = LabelEncoder()\n",
    "        df_with_genre['Genre'] = label_encoder.fit_transform(df_with_genre['Genre'])\n",
    "\n",
    "        # Modelo de clasificación de texto\n",
    "        text_clf = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english', max_features=1000)),\n",
    "            ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "        ])\n",
    "\n",
    "        # Entrenar el modelo con los datos disponibles\n",
    "        text_clf.fit(df_with_genre['Summary'], df_with_genre['Genre'])\n",
    "\n",
    "        # Predecir los géneros faltantes\n",
    "        predicted_genres = text_clf.predict(df_missing_genre['Summary'])\n",
    "\n",
    "        # Convertir las predicciones de vuelta a etiquetas originales\n",
    "        df_missing_genre['Genre'] = label_encoder.inverse_transform(predicted_genres)\n",
    "\n",
    "        # Combinar las filas con `Genre` y las predichas\n",
    "        df = pd.concat([df_with_genre, df_missing_genre])\n",
    "\n",
    "# Paso 7: Crear nuevas columnas derivadas\n",
    "def create_new_columns(df):\n",
    "    \"\"\"\n",
    "    Crea nuevas columnas derivadas basadas en la información existente.\n",
    "    \"\"\"\n",
    "    df['Game_Age'] = 2024 - df['Year']\n",
    "    \n",
    "    # Ratios regionales\n",
    "    df['NorthAmerica_Global_Ratio'] = df['North America'] / df['Global']\n",
    "    df['Europe_Global_Ratio'] = df['Europe'] / df['Global']\n",
    "    df['Japan_Global_Ratio'] = df['Japan'] / df['Global']\n",
    "    df['RestOfWorld_Global_Ratio'] = df['Rest of World'] / df['Global']\n",
    "\n",
    "    # Relación entre reseñas y wishlist\n",
    "    df['Reviews_Wishlist_Ratio'] = df['Number of Reviews'] / df['Wishlist']\n",
    "\n",
    "    # Interacciones categóricas\n",
    "    df['Publisher_Platform_Interaction'] = df['Publisher'] + df['Platform']\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_with_genre_and_columns(df):\n",
    "    # Limpiar datos\n",
    "    df = clean_data(df)\n",
    "\n",
    "    # Rellenar valores faltantes en `Genre` usando `Summary`\n",
    "    if 'Summary' in df.columns and 'Genre' in df.columns:\n",
    "        df = fill_missing_genres(df)\n",
    "\n",
    "    # Convertir columnas numéricas con valores inconsistentes\n",
    "    columns_to_convert = ['Europe', 'Japan', 'Rest of World', 'North America', \n",
    "                          'Global', 'Number of Reviews', 'Wishlist']\n",
    "    for col in columns_to_convert:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(convert_to_numeric)\n",
    "\n",
    "    # Manejar outliers\n",
    "    outlier_columns = ['Global', 'Wishlist']\n",
    "    df = handle_outliers(df, outlier_columns)\n",
    "\n",
    "    # Codificar columnas categóricas\n",
    "    categorical_columns = ['Game Title', 'Publisher', 'Platform', 'Genre']\n",
    "    df = encode_categorical(df, categorical_columns)\n",
    "\n",
    "    # Crear nuevas columnas derivadas\n",
    "    df = create_new_columns(df)\n",
    "\n",
    "    # Escalar columnas numéricas\n",
    "    numerical_columns = ['North America', 'Europe', 'Japan', 'Rest of World', \n",
    "                         'Global', 'Number of Reviews', 'Wishlist', 'Game_Age', \n",
    "                         'Europe_Global_Ratio', 'Japan_Global_Ratio', \n",
    "                         'NorthAmerica_Global_Ratio', 'RestOfWorld_Global_Ratio',\n",
    "                         'Reviews_Wishlist_Ratio']\n",
    "    df = scale_numerical(df, numerical_columns)\n",
    "\n",
    "    # Eliminar columnas irrelevantes\n",
    "    columns_to_drop = ['Game Title']\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "    # Eliminar las columnas regionales originales después de crear los ratios\n",
    "    columns_to_drop = ['North America', 'Europe', 'Japan', 'Rest of World']\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Aplicar el preprocesamiento actualizado\n",
    "df_train = preprocess_data_with_genre_and_columns(df_train)\n",
    "df_test = preprocess_data_with_genre_and_columns(df_test)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(\"Datos preprocesados con géneros rellenados y nuevas columnas (train):\")\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar correlación con la variable objetivo (para regresión)\n",
    "def evaluate_feature_correlation(X, y):\n",
    "    \"\"\"\n",
    "    Evalúa la correlación de cada característica con la variable objetivo.\n",
    "    Devuelve un DataFrame con las puntuaciones.\n",
    "    \"\"\"\n",
    "    selector = SelectKBest(score_func=f_regression, k='all')\n",
    "    selector.fit(X, y)\n",
    "    scores = selector.scores_\n",
    "\n",
    "    # Crear un DataFrame con las puntuaciones\n",
    "    feature_scores = pd.DataFrame({'Feature': X.columns, 'Score': scores})\n",
    "    feature_scores = feature_scores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "    print(\"Importancia de características basada en correlación:\")\n",
    "    print(feature_scores)\n",
    "    return feature_scores\n",
    "\n",
    "# Función para evaluar la importancia de características usando un modelo\n",
    "def evaluate_feature_importance_model(X, y):\n",
    "    \"\"\"\n",
    "    Evalúa la importancia de características utilizando un RandomForestRegressor.\n",
    "    Devuelve un DataFrame con las importancias.\n",
    "    \"\"\"\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X, y)\n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    # Crear un DataFrame con las importancias\n",
    "    feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "    feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Visualizar la importancia de características\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importances['Feature'], feature_importances['Importance'])\n",
    "    plt.xlabel(\"Importancia\")\n",
    "    plt.ylabel(\"Características\")\n",
    "    plt.title(\"Importancia de características según RandomForest\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Importancia de características basada en RandomForest:\")\n",
    "    print(feature_importances)\n",
    "    return feature_importances\n",
    "\n",
    "# Selección de las características más relevantes\n",
    "def select_top_features(X, y, k=10):\n",
    "    \"\"\"\n",
    "    Selecciona las k características más relevantes utilizando SelectKBest.\n",
    "    \"\"\"\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "    # Obtener las columnas seleccionadas\n",
    "    selected_columns = X.columns[selector.get_support()]\n",
    "    print(f\"Características seleccionadas ({k} mejores): {selected_columns}\")\n",
    "    return X_selected, selected_columns\n",
    "\n",
    "# Para df_train (como ya tienes)\n",
    "X_train = df_train.drop(columns=['Rating'])  # Variables predictoras\n",
    "y_train = df_train['Rating']  # Variable objetivo\n",
    "\n",
    "# Evaluar y seleccionar características en df_train\n",
    "correlation_scores = evaluate_feature_correlation(X_train, y_train)\n",
    "importance_scores = evaluate_feature_importance_model(X_train, y_train)\n",
    "X_train_selected, selected_columns = select_top_features(X_train, y_train, k=10)\n",
    "\n",
    "# Actualizar el dataset de entrenamiento\n",
    "df_train_selected = pd.DataFrame(X_train_selected, columns=selected_columns)\n",
    "df_train_selected['Rating'] = y_train  # Añadir la columna objetivo para usar en el modelo\n",
    "\n",
    "# Aplicar la misma selección de características al conjunto de prueba**\n",
    "if 'Rating' in df_test.columns:\n",
    "    X_test = df_test.drop(columns=['Rating'])  # Variables predictoras en el conjunto de prueba\n",
    "    y_test = df_test['Rating']  # Variable objetivo en el conjunto de prueba\n",
    "else:\n",
    "    X_test = df_test\n",
    "    y_test = None\n",
    "\n",
    "# Seleccionar las mismas características en df_test usando `selected_columns`\n",
    "X_test_selected = X_test[selected_columns]\n",
    "\n",
    "# Actualizar el dataset de prueba\n",
    "df_test_selected = pd.DataFrame(X_test_selected, columns=selected_columns)\n",
    "if y_test is not None:\n",
    "    df_test_selected['Rating'] = y_test  # Solo si `Rating` está disponible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceso de nuevo los datos eliminando columnas irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_optimized(df):\n",
    "\n",
    "    # Eliminar columnas menos relevantes\n",
    "    columns_to_drop = ['id', 'Publisher_Platform_Interaction', 'Publisher', 'Wishlist', \n",
    "                       'Number of Reviews', 'Reviews_Wishlist_Ratio']\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Aplicar el preprocesamiento optimizado\n",
    "df_train = preprocess_data_optimized(df_train)\n",
    "df_test = preprocess_data_optimized(df_test)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(\"Datos preprocesados optimizados (train):\")\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Función para evaluar correlación con la variable objetivo (para regresión)\n",
    "def evaluate_feature_correlation(X, y):\n",
    "    \"\"\"\n",
    "    Evalúa la correlación de cada característica con la variable objetivo.\n",
    "    Devuelve un DataFrame con las puntuaciones.\n",
    "    \"\"\"\n",
    "    selector = SelectKBest(score_func=f_regression, k='all')\n",
    "    selector.fit(X, y)\n",
    "    scores = selector.scores_\n",
    "\n",
    "    # Crear un DataFrame con las puntuaciones\n",
    "    feature_scores = pd.DataFrame({'Feature': X.columns, 'Score': scores})\n",
    "    feature_scores = feature_scores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "    print(\"Importancia de características basada en correlación:\")\n",
    "    print(feature_scores)\n",
    "    return feature_scores\n",
    "\n",
    "# Función para evaluar la importancia de características usando un modelo\n",
    "def evaluate_feature_importance_model(X, y):\n",
    "    \"\"\"\n",
    "    Evalúa la importancia de características utilizando un RandomForestRegressor.\n",
    "    Devuelve un DataFrame con las importancias.\n",
    "    \"\"\"\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X, y)\n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    # Crear un DataFrame con las importancias\n",
    "    feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "    feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Visualizar la importancia de características\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importances['Feature'], feature_importances['Importance'])\n",
    "    plt.xlabel(\"Importancia\")\n",
    "    plt.ylabel(\"Características\")\n",
    "    plt.title(\"Importancia de características según RandomForest\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Importancia de características basada en RandomForest:\")\n",
    "    print(feature_importances)\n",
    "    return feature_importances\n",
    "\n",
    "# Selección de las características más relevantes\n",
    "def select_top_features(X, y, k=10):\n",
    "    \"\"\"\n",
    "    Selecciona las k características más relevantes utilizando SelectKBest.\n",
    "    \"\"\"\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "    # Obtener las columnas seleccionadas\n",
    "    selected_columns = X.columns[selector.get_support()]\n",
    "    print(f\"Características seleccionadas ({k} mejores): {selected_columns}\")\n",
    "    return X_selected, selected_columns\n",
    "\n",
    "# Para df_train (como ya tienes)\n",
    "X_train = df_train.drop(columns=['Rating'])  # Variables predictoras\n",
    "y_train = df_train['Rating']  # Variable objetivo\n",
    "\n",
    "# Evaluar y seleccionar características en df_train\n",
    "correlation_scores = evaluate_feature_correlation(X_train, y_train)\n",
    "importance_scores = evaluate_feature_importance_model(X_train, y_train)\n",
    "X_train_selected, selected_columns = select_top_features(X_train, y_train, k=10)\n",
    "\n",
    "# Actualizar el dataset de entrenamiento\n",
    "df_train_selected = pd.DataFrame(X_train_selected, columns=selected_columns)\n",
    "df_train_selected['Rating'] = y_train  # Añadir la columna objetivo para usar en el modelo\n",
    "\n",
    "# Aplicar la misma selección de características al conjunto de prueba\n",
    "# Como no tiene la columna `Rating`, simplemente seleccionamos las columnas relevantes\n",
    "X_test = df_test[selected_columns]\n",
    "\n",
    "# Actualizar el dataset de prueba\n",
    "df_test_selected = pd.DataFrame(X_test, columns=selected_columns)\n",
    "\n",
    "# df_test_selected ahora contiene solo las características seleccionadas para hacer predicciones\n",
    "print(\"Características seleccionadas en el conjunto de prueba:\")\n",
    "print(df_test_selected.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y Evaluacion de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos para entrenamiento y prueba\n",
    "\n",
    "# Entrenamiento: X_train y y_train\n",
    "X_train = df_train_selected.drop(columns=['Rating'])  # Variables predictoras del conjunto de entrenamiento\n",
    "y_train = df_train_selected['Rating']  # Variable objetivo del conjunto de entrenamiento\n",
    "\n",
    "# Prueba: X_test (sin Rating)\n",
    "X_test = df_test_selected  # df_test seleccionado y procesado ya no incluye la columna Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear carpetas base para resultados\n",
    "os.makedirs(\"predictions/RegresionLineal\", exist_ok=True)\n",
    "os.makedirs(\"metrics/RegresionLineal\", exist_ok=True)\n",
    "os.makedirs(\"metrics/MejoresModelos\", exist_ok=True)\n",
    "\n",
    "# Función para entrenar y evaluar el modelo\n",
    "\n",
    "def train_and_evaluate_lr(X_train, y_train, X_test):\n",
    "    # Escalar los datos\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Configuración de hiperparámetros\n",
    "    param_grid_lr = {\n",
    "        'fit_intercept': [True, False],  # Ajustar o no el intercepto\n",
    "    }\n",
    "\n",
    "    # Entrenamiento y búsqueda de hiperparámetros\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        LinearRegression(),\n",
    "        param_grid_lr,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_search_lr.fit(X_train_scaled, y_train)\n",
    "    best_model = grid_search_lr.best_estimator_\n",
    "    print(f\"Mejores parámetros: {grid_search_lr.best_params_}\")\n",
    "\n",
    "    # Validación cruzada en el conjunto de entrenamiento\n",
    "    cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_mean = -cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "    cv_rmse = sqrt(cv_mean)\n",
    "\n",
    "    print(\"\\nValidación cruzada:\")\n",
    "    print(f\"MSE promedio (CV): {cv_mean:.4f}\")\n",
    "    print(f\"RMSE promedio (CV): {cv_rmse:.4f}\")\n",
    "    print(f\"Desviación estándar (MSE): {cv_std:.4f}\")\n",
    "\n",
    "    # Generar predicciones para el conjunto de prueba\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "    # Guardar predicciones en archivo CSV dentro de la carpeta `predictions/RegresionLineal`\n",
    "    predictions_file = f\"predictions/RegresionLineal/predicciones_regresion_lineal.csv\"\n",
    "    pd.DataFrame({\"Id\": range(len(y_pred)), \"Predicted_Rating\": y_pred}).to_csv(predictions_file, index=False)\n",
    "    print(f\"Predicciones guardadas en {predictions_file}\")\n",
    "\n",
    "    # Guardar métricas en archivo CSV dentro de `metrics/RegresionLineal`\n",
    "    metrics_file = f\"metrics/RegresionLineal/metrics_regresion_lineal.csv\"\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        f.write(\"Métrica,Valor\\n\")\n",
    "        f.write(f\"MSE promedio (CV),{cv_mean:.4f}\\n\")\n",
    "        f.write(f\"RMSE promedio (CV),{cv_rmse:.4f}\\n\")\n",
    "        f.write(f\"Desviación estándar (MSE),{cv_std:.4f}\\n\")\n",
    "    print(f\"Métricas guardadas en {metrics_file}\")\n",
    "\n",
    "    return cv_mean, cv_std, metrics_file, best_model\n",
    "\n",
    "# Proceso principal para obtener el mejor modelo\n",
    "def main_lr(X_train, y_train, X_test):\n",
    "    cv_mean, cv_std, metrics_file, best_model = train_and_evaluate_lr(X_train, y_train, X_test)\n",
    "\n",
    "    # Guardar métricas del mejor modelo en archivo CSV\n",
    "    best_metrics_file = \"metrics/MejoresModelos/LR_mejor_modelo.csv\"\n",
    "    with open(best_metrics_file, \"w\") as f:\n",
    "        f.write(\"Métrica,Valor\\n\")\n",
    "        f.write(f\"MSE promedio (CV),{cv_mean:.4f}\\n\")\n",
    "        f.write(f\"RMSE promedio (CV),{sqrt(cv_mean):.4f}\\n\")\n",
    "        f.write(f\"Desviación estándar (MSE),{cv_std:.4f}\\n\")\n",
    "    print(f\"Métricas del mejor modelo guardadas en {best_metrics_file}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Llamar al proceso principal\n",
    "best_model = main_lr(X_train, y_train, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con regularizacion ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear carpetas base para resultados\n",
    "os.makedirs(\"predictions/RidgeRegression\", exist_ok=True)\n",
    "os.makedirs(\"metrics/RidgeRegression\", exist_ok=True)\n",
    "os.makedirs(\"metrics/MejoresModelos\", exist_ok=True)\n",
    "\n",
    "def train_and_evaluate_ridge(X_train, y_train, X_test, alpha, fit_intercept):\n",
    "    # Configuración de hiperparámetros\n",
    "    param_grid_ridge = {\n",
    "        'alpha': [alpha],  # Regularización L2\n",
    "        'fit_intercept': [fit_intercept]\n",
    "    }\n",
    "\n",
    "    # Modelo base Ridge\n",
    "    ridge_model = Ridge()\n",
    "\n",
    "    # Optimización con GridSearchCV\n",
    "    grid_search_ridge = GridSearchCV(\n",
    "        estimator=ridge_model,\n",
    "        param_grid=param_grid_ridge,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Entrenar el modelo con los datos de entrenamiento\n",
    "    grid_search_ridge.fit(X_train, y_train)\n",
    "    best_model = grid_search_ridge.best_estimator_\n",
    "\n",
    "    print(f\"Mejores parámetros para alpha={alpha}, fit_intercept={fit_intercept}: {grid_search_ridge.best_params_}\")\n",
    "\n",
    "    # Validación cruzada\n",
    "    cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_mean = -cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "    cv_rmse = np.sqrt(cv_mean)\n",
    "\n",
    "    print(\"\\nValidación cruzada:\")\n",
    "    print(f\"MSE promedio (CV): {cv_mean:.4f}\")\n",
    "    print(f\"RMSE promedio (CV): {cv_rmse:.4f}\")\n",
    "    print(f\"Desviación estándar (MSE): {cv_std:.4f}\")\n",
    "\n",
    "    # Predicciones en el conjunto de prueba\n",
    "    y_pred = best_model.predict(X_test)  # Sin limitación de resultados\n",
    "\n",
    "    # Guardar predicciones\n",
    "    predictions_file = f\"predictions/RidgeRegression/predicciones_alpha_{alpha}_fit_intercept_{fit_intercept}.csv\"\n",
    "    pd.DataFrame({\"Id\": range(len(y_pred)), \"Predicted_Rating\": y_pred}).to_csv(predictions_file, index=False)\n",
    "    print(f\"Predicciones guardadas en {predictions_file}\")\n",
    "\n",
    "    # Guardar métricas\n",
    "    metrics_file = f\"metrics/RidgeRegression/metrics_alpha_{alpha}_fit_intercept_{fit_intercept}.csv\"\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        f.write(\"Métrica,Valor\\n\")\n",
    "        f.write(f\"MSE promedio (CV),{cv_mean:.4f}\\n\")\n",
    "        f.write(f\"RMSE promedio (CV),{cv_rmse:.4f}\\n\")\n",
    "        f.write(f\"Desviación estándar (MSE),{cv_std:.4f}\\n\")\n",
    "    print(f\"Métricas guardadas en {metrics_file}\")\n",
    "\n",
    "    return cv_mean, cv_std, metrics_file, best_model\n",
    "\n",
    "def main_ridge(X_train, y_train, X_test):\n",
    "    results = []\n",
    "    alpha_values = [0.1, 1, 10]\n",
    "    fit_intercept_values = [True, False]\n",
    "\n",
    "    # Iterar sobre diferentes combinaciones de hiperparámetros\n",
    "    for alpha in alpha_values:\n",
    "        for fit_intercept in fit_intercept_values:\n",
    "            cv_mean, cv_std, metrics_file, model = train_and_evaluate_ridge(X_train, y_train, X_test, alpha, fit_intercept)\n",
    "            results.append((alpha, fit_intercept, cv_mean, cv_std, metrics_file, model))\n",
    "\n",
    "    # Seleccionar el mejor modelo basado en MSE promedio\n",
    "    best_model = min(results, key=lambda x: x[2])\n",
    "    print(\"\\nMejor modelo:\")\n",
    "    print(f\"alpha: {best_model[0]}, fit_intercept: {best_model[1]}, MSE promedio: {best_model[2]:.4f}\")\n",
    "\n",
    "    # Guardar métricas del mejor modelo en archivo CSV\n",
    "    best_metrics_file = \"metrics/MejoresModelos/Ridge_mejor_modelo.csv\"\n",
    "    with open(best_metrics_file, \"w\") as f:\n",
    "        f.write(\"Métrica,Valor\\n\")\n",
    "        f.write(f\"MSE promedio (CV),{best_model[2]:.4f}\\n\")\n",
    "        f.write(f\"RMSE promedio (CV),{np.sqrt(best_model[2]):.4f}\\n\")\n",
    "        f.write(f\"Desviación estándar (MSE),{best_model[3]:.4f}\\n\")\n",
    "    print(f\"Métricas del mejor modelo guardadas en {best_metrics_file}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Llamar al proceso principal\n",
    "best_model = main_ridge(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arboles de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear carpetas base para resultados\n",
    "os.makedirs(\"predictions/ArbolesDeDecision\", exist_ok=True)\n",
    "os.makedirs(\"metrics/ArbolesDeDecision\", exist_ok=True)\n",
    "os.makedirs(\"metrics/MejoresModelos\", exist_ok=True)\n",
    "\n",
    "# Función para entrenar y evaluar un modelo con un conjunto de hiperparámetros\n",
    "def train_and_evaluate_tree(X_train, y_train, X_test, max_depth, criterion, max_features):\n",
    "    # Configuración de hiperparámetros\n",
    "    param_grid_tree = {\n",
    "        'max_depth': [max_depth],\n",
    "        'criterion': [criterion],\n",
    "        'max_features': [max_features],\n",
    "        'min_samples_leaf': [5, 10],\n",
    "        'min_impurity_decrease': [0.0],  # Valor fijo para este caso\n",
    "        'splitter': ['best']\n",
    "    }\n",
    "    \n",
    "    # Entrenamiento y búsqueda de hiperparámetros\n",
    "    grid_search_tree = GridSearchCV(\n",
    "        DecisionTreeRegressor(random_state=42),\n",
    "        param_grid_tree,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search_tree.fit(X_train, y_train)\n",
    "    best_model = grid_search_tree.best_estimator_\n",
    "    print(f\"Mejores parámetros para max_depth={max_depth}, criterion={criterion}, max_features={max_features}: {grid_search_tree.best_params_}\")\n",
    "    \n",
    "    # Validación cruzada en el conjunto de entrenamiento\n",
    "    cv_scores_mse = cross_val_score(best_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_mean_mse = -cv_scores_mse.mean()\n",
    "    cv_std_mse = cv_scores_mse.std()\n",
    "    cv_rmse = sqrt(cv_mean_mse)\n",
    "    \n",
    "    print(\"\\nValidación cruzada:\")\n",
    "    print(f\"MSE promedio (CV): {cv_mean_mse:.4f}\")\n",
    "    print(f\"RMSE promedio (CV): {cv_rmse:.4f}\")\n",
    "    print(f\"Desviación estándar (MSE): {cv_std_mse:.4f}\")\n",
    "    \n",
    "    # Generar predicciones para el conjunto de prueba\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Guardar predicciones en archivo CSV dentro de la carpeta `predictions/ArbolesDeDecision`\n",
    "    predictions_file = f\"predictions/ArbolesDeDecision/predicciones_max_depth_{max_depth}_criterion_{criterion}_features_{max_features}.csv\"\n",
    "    pd.DataFrame({\"Id\": range(len(y_pred)), \"Predicted_Rating\": y_pred}).to_csv(predictions_file, index=False)\n",
    "    print(f\"Predicciones guardadas en {predictions_file}\")\n",
    "    \n",
    "    # Guardar métricas en archivo CSV dentro de `metrics/ArbolesDeDecision`\n",
    "    metrics_file = f\"metrics/ArbolesDeDecision/metrics_max_depth_{max_depth}_criterion_{criterion}_features_{max_features}.csv\"\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        f.write(\"Métrica,Valor\\n\")\n",
    "        f.write(f\"MSE promedio (CV),{cv_mean_mse:.4f}\\n\")\n",
    "        f.write(f\"RMSE promedio (CV),{cv_rmse:.4f}\\n\")\n",
    "        f.write(f\"Desviación estándar (MSE),{cv_std_mse:.4f}\\n\")\n",
    "    print(f\"Métricas guardadas en {metrics_file}\")\n",
    "    \n",
    "    return cv_mean_mse, cv_std_mse, metrics_file, best_model\n",
    "\n",
    "# Proceso principal para iterar sobre los hiperparámetros\n",
    "def main_tree(X_train, y_train, X_test):\n",
    "    results = []\n",
    "    max_depth_values = [3, 7, 15]\n",
    "    criterion_values = ['squared_error', 'absolute_error']  # Cambiar a criterios válidos\n",
    "    max_features_values = ['sqrt', 'log2']\n",
    "    \n",
    "    # Iterar sobre diferentes combinaciones de hiperparámetros\n",
    "    for max_depth in max_depth_values:\n",
    "        for criterion in criterion_values:\n",
    "            for max_features in max_features_values:\n",
    "                cv_mean_mse, cv_std_mse, metrics_file, model = train_and_evaluate_tree(\n",
    "                    X_train, y_train, X_test, max_depth, criterion, max_features\n",
    "                )\n",
    "                results.append((max_depth, criterion, max_features, cv_mean_mse, cv_std_mse, metrics_file, model))\n",
    "    \n",
    "    # Seleccionar el mejor modelo basado en MSE promedio\n",
    "    best_model = min(results, key=lambda x: x[3])\n",
    "    print(\"\\nMejor modelo:\")\n",
    "    print(f\"max_depth: {best_model[0]}, criterion: {best_model[1]}, max_features: {best_model[2]}, MSE promedio: {best_model[3]:.4f}\")\n",
    "    \n",
    "    # Guardar métricas del mejor modelo en archivo CSV\n",
    "    best_metrics_file = \"metrics/MejoresModelos/DT_mejor_modelo.csv\"\n",
    "    with open(best_metrics_file, \"w\") as f:\n",
    "        f.write(\"Métrica,Valor\\n\")\n",
    "        f.write(f\"MSE promedio (CV),{best_model[3]:.4f}\\n\")\n",
    "        f.write(f\"RMSE promedio (CV),{sqrt(best_model[3]):.4f}\\n\")\n",
    "        f.write(f\"Desviación estándar (MSE),{best_model[4]:.4f}\\n\")\n",
    "    print(f\"Métricas del mejor modelo guardadas en {best_metrics_file}\")\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Llamar al proceso principal\n",
    "best_model = main_tree(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear carpetas base para resultados\n",
    "os.makedirs(\"predictions/RandomForest\", exist_ok=True)\n",
    "os.makedirs(\"metrics/RandomForest\", exist_ok=True)\n",
    "os.makedirs(\"metrics/MejoresModelos\", exist_ok=True)\n",
    "\n",
    "# Función para entrenar y evaluar un modelo con un conjunto de hiperparámetros\n",
    "def train_and_evaluate_rf(X_train, y_train, X_test, n_estimators, max_depth):\n",
    "    # Configuración de hiperparámetros\n",
    "    param_grid_rf = {\n",
    "        'n_estimators': [n_estimators],\n",
    "        'max_depth': [max_depth],\n",
    "        'min_samples_split': [2],\n",
    "        'min_samples_leaf': [1]\n",
    "    }\n",
    "\n",
    "    # Entrenamiento y búsqueda de hiperparámetros\n",
    "    grid_search_rf = GridSearchCV(\n",
    "        RandomForestRegressor(random_state=42),\n",
    "        param_grid_rf,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_search_rf.fit(X_train, y_train)\n",
    "    best_model = grid_search_rf.best_estimator_\n",
    "    print(f\"Mejores parámetros para n_estimators={n_estimators}, max_depth={max_depth}: {grid_search_rf.best_params_}\")\n",
    "\n",
    "    # Validación cruzada en el conjunto de entrenamiento\n",
    "    cv_scores_mse = cross_val_score(best_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_mean_mse = -cv_scores_mse.mean()\n",
    "    cv_std_mse = cv_scores_mse.std()\n",
    "    cv_rmse = sqrt(cv_mean_mse)\n",
    "\n",
    "    print(\"\\nValidación cruzada:\")\n",
    "    print(f\"MSE promedio (CV): {cv_mean_mse:.4f}\")\n",
    "    print(f\"RMSE promedio (CV): {cv_rmse:.4f}\")\n",
    "    print(f\"Desviación estándar (MSE): {cv_std_mse:.4f}\")\n",
    "\n",
    "    # Generar predicciones para el conjunto de prueba\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Guardar predicciones en archivo CSV dentro de la carpeta `predictions/RandomForest`\n",
    "    predictions_file = f\"predictions/RandomForest/predicciones_n_estimators_{n_estimators}_max_depth_{max_depth}.csv\"\n",
    "    pd.DataFrame({\"Id\": range(len(y_pred)), \"Predicted_Rating\": y_pred}).to_csv(predictions_file, index=False)\n",
    "    print(f\"Predicciones guardadas en {predictions_file}\")\n",
    "\n",
    "    # Guardar métricas en archivo CSV dentro de `metrics/RandomForest`\n",
    "    metrics_file = f\"metrics/RandomForest/metrics_n_estimators_{n_estimators}_max_depth_{max_depth}.csv\"\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        f.write(\"Métrica,Valor\\n\")\n",
    "        f.write(f\"MSE promedio (CV),{cv_mean_mse:.4f}\\n\")\n",
    "        f.write(f\"RMSE promedio (CV),{cv_rmse:.4f}\\n\")\n",
    "        f.write(f\"Desviación estándar (MSE),{cv_std_mse:.4f}\\n\")\n",
    "    print(f\"Métricas guardadas en {metrics_file}\")\n",
    "\n",
    "    return cv_mean_mse, cv_std_mse, metrics_file, best_model\n",
    "\n",
    "# Proceso principal para iterar sobre los hiperparámetros\n",
    "def main_rf(X_train, y_train, X_test):\n",
    "    results = []\n",
    "    n_estimators_values = [50, 100]\n",
    "    max_depth_values = [5, 10, 20]\n",
    "\n",
    "    # Iterar sobre diferentes combinaciones de n_estimators y max_depth\n",
    "    for n_estimators in n_estimators_values:\n",
    "        for max_depth in max_depth_values:\n",
    "            cv_mean_mse, cv_std_mse, metrics_file, model = train_and_evaluate_rf(X_train, y_train, X_test, n_estimators, max_depth)\n",
    "            results.append((n_estimators, max_depth, cv_mean_mse, cv_std_mse, metrics_file, model))\n",
    "\n",
    "    # Seleccionar el mejor modelo basado en MSE promedio\n",
    "    best_model = min(results, key=lambda x: x[2])\n",
    "    print(\"\\nMejor modelo:\")\n",
    "    print(f\"n_estimators: {best_model[0]}, max_depth: {best_model[1]}, MSE promedio: {best_model[2]:.4f}\")\n",
    "\n",
    "    # Guardar métricas del mejor modelo en archivo CSV\n",
    "    best_metrics_file = \"metrics/MejoresModelos/RF_mejor_modelo.csv\"\n",
    "    with open(best_metrics_file, \"w\") as f:\n",
    "        f.write(\"Métrica,Valor\\n\")\n",
    "        f.write(f\"MSE promedio (CV),{best_model[2]:.4f}\\n\")\n",
    "        f.write(f\"RMSE promedio (CV),{sqrt(best_model[2]):.4f}\\n\")\n",
    "        f.write(f\"Desviación estándar (MSE),{best_model[3]:.4f}\\n\")\n",
    "    print(f\"Métricas del mejor modelo guardadas en {best_metrics_file}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Llamar al proceso principal\n",
    "best_model = main_rf(X_train, y_train, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear carpetas base para resultados\n",
    "os.makedirs(\"predictions/GradientBoosting\", exist_ok=True)\n",
    "os.makedirs(\"metrics/GradientBoosting\", exist_ok=True)\n",
    "os.makedirs(\"metrics/MejoresModelos\", exist_ok=True)\n",
    "\n",
    "# Función para entrenar y evaluar un modelo con un conjunto de hiperparámetros\n",
    "def train_and_evaluate_gb(X_train, y_train, X_test, n_estimators, learning_rate):\n",
    "    # Configuración de hiperparámetros\n",
    "    param_grid_gb = {\n",
    "        'n_estimators': [n_estimators],\n",
    "        'learning_rate': [learning_rate],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 1.0],\n",
    "    }\n",
    "    \n",
    "    # Entrenamiento y búsqueda de hiperparámetros\n",
    "    grid_search_gb = GridSearchCV(\n",
    "        GradientBoostingRegressor(random_state=42),\n",
    "        param_grid_gb,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search_gb.fit(X_train, y_train)\n",
    "    best_model = grid_search_gb.best_estimator_\n",
    "    print(f\"Mejores parámetros para n_estimators={n_estimators}, learning_rate={learning_rate}: {grid_search_gb.best_params_}\")\n",
    "    \n",
    "    # Validación cruzada en el conjunto de entrenamiento\n",
    "    cv_scores_mse = cross_val_score(best_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_mean_mse = -cv_scores_mse.mean()\n",
    "    cv_std_mse = cv_scores_mse.std()\n",
    "    cv_rmse = sqrt(cv_mean_mse)\n",
    "    \n",
    "    print(\"\\nValidación cruzada:\")\n",
    "    print(f\"MSE promedio (CV): {cv_mean_mse:.4f}\")\n",
    "    print(f\"RMSE promedio (CV): {cv_rmse:.4f}\")\n",
    "    print(f\"Desviación estándar (MSE): {cv_std_mse:.4f}\")\n",
    "    \n",
    "    # Generar predicciones para el conjunto de prueba\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Guardar predicciones en archivo CSV dentro de la carpeta `predictions/GradientBoosting`\n",
    "    predictions_file = f\"predictions/GradientBoosting/predicciones_n_estimators_{n_estimators}_lr_{learning_rate}.csv\"\n",
    "    pd.DataFrame({\"Id\": range(len(y_pred)), \"Predicted_Rating\": y_pred}).to_csv(predictions_file, index=False)\n",
    "    print(f\"Predicciones guardadas en {predictions_file}\")\n",
    "    \n",
    "    # Guardar métricas en archivo CSV dentro de `metrics/GradientBoosting`\n",
    "    metrics_file = f\"metrics/GradientBoosting/metrics_n_estimators_{n_estimators}_lr_{learning_rate}.csv\"\n",
    "    metrics_table = pd.DataFrame({\n",
    "        \"Métrica\": [\"MSE promedio (CV)\", \"RMSE promedio (CV)\", \"Desviación estándar (MSE)\"],\n",
    "        \"Valor\": [cv_mean_mse, cv_rmse, cv_std_mse]\n",
    "    })\n",
    "    metrics_table.to_csv(metrics_file, index=False)\n",
    "    print(f\"Métricas guardadas en {metrics_file}\")\n",
    "    \n",
    "    return cv_mean_mse, metrics_file, best_model\n",
    "\n",
    "# Proceso principal para iterar sobre los hiperparámetros\n",
    "def main_gb(X_train, y_train, X_test):\n",
    "    results = []\n",
    "    n_estimators_values = [50, 100, 200]\n",
    "    learning_rate_values = [0.01, 0.1, 0.2]\n",
    "    \n",
    "    # Iterar sobre diferentes combinaciones de n_estimators y learning_rate\n",
    "    for n_estimators in n_estimators_values:\n",
    "        for learning_rate in learning_rate_values:\n",
    "            cv_mean_mse, metrics_file, model = train_and_evaluate_gb(\n",
    "                X_train, y_train, X_test, n_estimators, learning_rate\n",
    "            )\n",
    "            results.append((n_estimators, learning_rate, cv_mean_mse, metrics_file, model))\n",
    "    \n",
    "    # Seleccionar el mejor modelo basado en MSE promedio\n",
    "    best_model = min(results, key=lambda x: x[2])\n",
    "    print(\"\\nMejor modelo:\")\n",
    "    print(f\"n_estimators: {best_model[0]}, learning_rate: {best_model[1]}, MSE promedio: {best_model[2]:.4f}\")\n",
    "    \n",
    "    # Guardar métricas del mejor modelo en `metrics/MejoresModelos/GB_mejor_modelo.csv`\n",
    "    best_metrics_file = \"metrics/MejoresModelos/GB_mejor_modelo.csv\"\n",
    "    pd.read_csv(best_model[3]).to_csv(best_metrics_file, index=False)\n",
    "    print(f\"Métricas del mejor modelo guardadas en {best_metrics_file}\")\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Llamar al proceso principal\n",
    "best_model = main_gb(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear carpetas base para resultados\n",
    "os.makedirs(\"predictions/AdaBoost\", exist_ok=True)\n",
    "os.makedirs(\"metrics/AdaBoost\", exist_ok=True)\n",
    "os.makedirs(\"metrics/MejoresModelos\", exist_ok=True)\n",
    "\n",
    "# Función para entrenar y evaluar un modelo con un conjunto de hiperparámetros\n",
    "def train_and_evaluate_ada(X_train, y_train, X_test, n_estimators, learning_rate):\n",
    "    # Configuración de hiperparámetros\n",
    "    param_grid_ada = {\n",
    "        'n_estimators': [n_estimators],  # Número de árboles\n",
    "        'learning_rate': [learning_rate],  # Tasa de aprendizaje\n",
    "        'estimator__max_depth': [5, 7, 10]  # No cambiar esta fila\n",
    "    }\n",
    "    \n",
    "    # Modelo base de AdaBoost con DecisionTreeRegressor\n",
    "    base_estimator = DecisionTreeRegressor(random_state=42)\n",
    "    ada_model = AdaBoostRegressor(estimator=base_estimator, random_state=42)\n",
    "    \n",
    "    # Optimización con GridSearchCV\n",
    "    grid_search_ada = GridSearchCV(\n",
    "        estimator=ada_model,\n",
    "        param_grid=param_grid_ada,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search_ada.fit(X_train, y_train)\n",
    "    best_model = grid_search_ada.best_estimator_\n",
    "    print(f\"Mejores parámetros para n_estimators={n_estimators}, learning_rate={learning_rate}: {grid_search_ada.best_params_}\")\n",
    "    \n",
    "    # Validación cruzada en el conjunto de entrenamiento\n",
    "    cv_scores_mse = cross_val_score(best_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_mean_mse = -cv_scores_mse.mean()\n",
    "    cv_std_mse = cv_scores_mse.std()\n",
    "    cv_rmse = np.sqrt(cv_mean_mse)\n",
    "    \n",
    "    print(\"\\nValidación cruzada:\")\n",
    "    print(f\"MSE promedio (CV): {cv_mean_mse:.4f}\")\n",
    "    print(f\"RMSE promedio (CV): {cv_rmse:.4f}\")\n",
    "    print(f\"Desviación estándar (MSE): {cv_std_mse:.4f}\")\n",
    "    \n",
    "    # Generar predicciones para el conjunto de prueba\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Guardar predicciones en archivo CSV dentro de la carpeta `predictions/AdaBoost`\n",
    "    predictions_file = f\"predictions/AdaBoost/predicciones_n_estimators_{n_estimators}_lr_{learning_rate}.csv\"\n",
    "    pd.DataFrame({\"Id\": range(len(y_pred)), \"Predicted_Rating\": y_pred}).to_csv(predictions_file, index=False)\n",
    "    print(f\"Predicciones guardadas en {predictions_file}\")\n",
    "    \n",
    "    # Guardar métricas en archivo CSV dentro de `metrics/AdaBoost`\n",
    "    metrics_file = f\"metrics/AdaBoost/metrics_n_estimators_{n_estimators}_lr_{learning_rate}.csv\"\n",
    "    metrics_table = pd.DataFrame({\n",
    "        \"Métrica\": [\"MSE promedio (CV)\", \"RMSE promedio (CV)\", \"Desviación estándar (MSE)\"],\n",
    "        \"Valor\": [cv_mean_mse, cv_rmse, cv_std_mse]\n",
    "    })\n",
    "    metrics_table.to_csv(metrics_file, index=False)\n",
    "    print(f\"Métricas guardadas en {metrics_file}\")\n",
    "    \n",
    "    return cv_mean_mse, metrics_file, best_model\n",
    "\n",
    "# Proceso principal para iterar sobre los hiperparámetros\n",
    "def main_ada(X_train, y_train, X_test):\n",
    "    results = []\n",
    "    n_estimators_values = [50, 100, 200]\n",
    "    learning_rate_values = [0.01, 0.1, 0.2]\n",
    "    \n",
    "    # Iterar sobre diferentes combinaciones de n_estimators y learning_rate\n",
    "    for n_estimators in n_estimators_values:\n",
    "        for learning_rate in learning_rate_values:\n",
    "            cv_mean_mse, metrics_file, model = train_and_evaluate_ada(\n",
    "                X_train, y_train, X_test, n_estimators, learning_rate\n",
    "            )\n",
    "            results.append((n_estimators, learning_rate, cv_mean_mse, metrics_file, model))\n",
    "    \n",
    "    # Seleccionar el mejor modelo basado en MSE promedio\n",
    "    best_model = min(results, key=lambda x: x[2])\n",
    "    print(\"\\nMejor modelo:\")\n",
    "    print(f\"n_estimators: {best_model[0]}, learning_rate: {best_model[1]}, MSE promedio: {best_model[2]:.4f}\")\n",
    "    \n",
    "    # Guardar métricas del mejor modelo en `metrics/MejoresModelos/AdaBoost_mejor_modelo.csv`\n",
    "    best_metrics_file = \"metrics/MejoresModelos/AdaBoost_mejor_modelo.csv\"\n",
    "    pd.read_csv(best_model[3]).to_csv(best_metrics_file, index=False)\n",
    "    print(f\"Métricas del mejor modelo guardadas en {best_metrics_file}\")\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Llamar al proceso principal\n",
    "best_model = main_ada(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear carpetas base para resultados\n",
    "os.makedirs(\"predictions/RedesNeuronales\", exist_ok=True)\n",
    "os.makedirs(\"metrics/RedesNeuronales\", exist_ok=True)\n",
    "os.makedirs(\"metrics/MejoresModelos\", exist_ok=True)\n",
    "\n",
    "# Función para entrenar y evaluar Redes Neuronales\n",
    "def train_and_evaluate_nn(X_train, y_train, X_test, hidden_layer_sizes, learning_rate_init):\n",
    "    # Configuración de hiperparámetros\n",
    "    param_grid_mlp = {\n",
    "        'hidden_layer_sizes': [hidden_layer_sizes],  # Capas ocultas pasadas como argumento\n",
    "        'activation': ['relu'],  # Fijo\n",
    "        'solver': ['adam'],  # Fijo\n",
    "        'alpha': [0.001],  # Regularización L2 fija\n",
    "        'learning_rate_init': [learning_rate_init],  # Tasa de aprendizaje pasada como argumento\n",
    "        'max_iter': [300],  # Fijo\n",
    "    }\n",
    "\n",
    "    # Optimización con GridSearchCV\n",
    "    grid_search_mlp = GridSearchCV(\n",
    "        MLPRegressor(random_state=42),\n",
    "        param_grid_mlp,\n",
    "        cv=5,  # Validación cruzada con 5 folds\n",
    "        scoring='neg_mean_squared_error',\n",
    "        verbose=1,\n",
    "        n_jobs=-1  # Paralelización\n",
    "    )\n",
    "\n",
    "    # Entrenar el modelo con los datos escalados\n",
    "    grid_search_mlp.fit(X_train, y_train)\n",
    "\n",
    "    # Mejor modelo encontrado\n",
    "    best_mlp_model = grid_search_mlp.best_estimator_\n",
    "    print(f\"Mejores parámetros para hidden_layer_sizes={hidden_layer_sizes}, learning_rate_init={learning_rate_init}: {grid_search_mlp.best_params_}\")\n",
    "\n",
    "    # Validación cruzada en el conjunto de entrenamiento\n",
    "    cv_scores_mse = cross_val_score(best_mlp_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_mean_mse = -cv_scores_mse.mean()  # MSE promedio (convertido a positivo)\n",
    "    cv_std_mse = cv_scores_mse.std()  # Desviación estándar del MSE\n",
    "    cv_rmse = np.sqrt(cv_mean_mse)  # RMSE promedio\n",
    "\n",
    "    print(\"\\nValidación cruzada para Redes Neuronales:\")\n",
    "    print(f\"Error Cuadrático Medio (MSE) promedio en validación cruzada: {cv_mean_mse:.4f}\")\n",
    "    print(f\"Raíz del Error Cuadrático Medio (RMSE) promedio en validación cruzada: {cv_rmse:.4f}\")\n",
    "    print(f\"Desviación estándar del MSE en validación cruzada: {cv_std_mse:.4f}\")\n",
    "\n",
    "    # Generar predicciones para el conjunto de prueba\n",
    "    y_pred = best_mlp_model.predict(X_test)\n",
    "\n",
    "    # Guardar predicciones en archivo CSV dentro de la carpeta `predictions/RedesNeuronales`\n",
    "    predictions_file = f\"predictions/RedesNeuronales/predicciones_hidden_{hidden_layer_sizes}_lr_{learning_rate_init}.csv\"\n",
    "    pd.DataFrame({\n",
    "        \"Id\": range(len(y_pred)),\n",
    "        \"Predicted_Rating\": y_pred\n",
    "    }).to_csv(predictions_file, index=False)\n",
    "    print(f\"Predicciones guardadas en '{predictions_file}'.\")\n",
    "\n",
    "    # Guardar métricas en archivo CSV dentro de `metrics/RedesNeuronales`\n",
    "    metrics_file = f\"metrics/RedesNeuronales/metrics_hidden_{hidden_layer_sizes}_lr_{learning_rate_init}.csv\"\n",
    "    metrics_table = pd.DataFrame({\n",
    "        \"Métrica\": [\"MSE promedio (CV)\", \"RMSE promedio (CV)\", \"Desviación estándar (MSE)\"],\n",
    "        \"Valor\": [cv_mean_mse, cv_rmse, cv_std_mse]\n",
    "    })\n",
    "    metrics_table.to_csv(metrics_file, index=False)\n",
    "    print(f\"Métricas guardadas en '{metrics_file}'.\")\n",
    "\n",
    "    return cv_mean_mse, metrics_file, best_mlp_model\n",
    "\n",
    "# Proceso principal para iterar sobre los hiperparámetros\n",
    "def main_nn(X_train, y_train, X_test):\n",
    "    results = []\n",
    "    hidden_layer_sizes_values = [(50,), (50, 50), (100, 50)]\n",
    "    learning_rate_values = [0.001, 0.01]\n",
    "\n",
    "    # Iterar sobre diferentes combinaciones de hidden_layer_sizes y learning_rate_init\n",
    "    for hidden_layer_sizes in hidden_layer_sizes_values:\n",
    "        for learning_rate_init in learning_rate_values:\n",
    "            cv_mean_mse, metrics_file, model = train_and_evaluate_nn(\n",
    "                X_train, y_train, X_test, hidden_layer_sizes, learning_rate_init\n",
    "            )\n",
    "            results.append((hidden_layer_sizes, learning_rate_init, cv_mean_mse, metrics_file, model))\n",
    "\n",
    "    # Seleccionar el mejor modelo basado en MSE promedio\n",
    "    best_model = min(results, key=lambda x: x[2])\n",
    "    print(\"\\nMejor modelo:\")\n",
    "    print(f\"hidden_layer_sizes: {best_model[0]}, learning_rate_init: {best_model[1]}, MSE promedio: {best_model[2]:.4f}\")\n",
    "\n",
    "    # Guardar métricas del mejor modelo en `metrics/MejoresModelos/NN_mejor_modelo.csv`\n",
    "    best_metrics_file = \"metrics/MejoresModelos/NN_mejor_modelo.csv\"\n",
    "    pd.read_csv(best_model[3]).to_csv(best_metrics_file, index=False)\n",
    "    print(f\"Métricas del mejor modelo guardadas en '{best_metrics_file}'.\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Escalar los datos (muy importante para redes neuronales)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Llamar al proceso principal\n",
    "best_model = main_nn(X_train_scaled, y_train, X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportacion de predicciones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
