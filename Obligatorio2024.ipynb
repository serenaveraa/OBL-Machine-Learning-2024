{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obligatorio - Machine Learning\n",
    "\n",
    "\n",
    "\n",
    "# Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones principales\n",
    "import pandas as pd  # Manejo y análisis de datos estructurados (DataFrames)\n",
    "import numpy as np  # Operaciones numéricas y manejo de arrays\n",
    "\n",
    "# Visualización de datos\n",
    "import matplotlib.pyplot as plt  # Visualización y gráficos\n",
    "\n",
    "# Preprocesamiento y selección de características\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  # Codificación de variables categóricas y escalado de datos\n",
    "from sklearn.feature_selection import f_regression, SelectKBest  # Selección de características relevantes basadas en correlación\n",
    "\n",
    "# Modelos de aprendizaje supervisado\n",
    "from sklearn.linear_model import LinearRegression, Ridge  # Modelos lineales para regresión\n",
    "from sklearn.tree import DecisionTreeRegressor  # Árboles de decisión para regresión\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor  # Modelos avanzados\n",
    "from sklearn.neural_network import MLPRegressor  # Redes neuronales para regresión\n",
    "\n",
    "# Evaluación y optimización\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score  # Dividir datos, búsqueda de hiperparámetros y validación cruzada\n",
    "from sklearn.metrics import (  # Métricas de evaluación para modelos de regresión\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    median_absolute_error,\n",
    "    r2_score,\n",
    "    max_error,\n",
    ")\n",
    "\n",
    "# Text Mining\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Representación numérica de texto (TF-IDF)\n",
    "\n",
    "# Utilidades estadísticas y preprocesamiento avanzado\n",
    "from scipy.stats.mstats import winsorize  # Manejo de valores extremos (outliers) mediante winsorización\n",
    "\n",
    "# Herramientas de pipeline\n",
    "from sklearn.pipeline import Pipeline  # Construcción de pipelines para flujos de preprocesamiento y modelado\n",
    "\n",
    "# Weights and Biases\n",
    "import wandb # Herramienta para el registro de experimentos y seguimiento de modelos\n",
    "\n",
    "# Utilidades generales\n",
    "import os\n",
    "from math import sqrt  # Función matemática para la raíz cuadrada\n",
    "\n",
    "# Cargar datasets\n",
    "df_train = pd.read_csv('./dataset/train.csv')  # Cargar el conjunto de entrenamiento\n",
    "df_test = pd.read_csv('./dataset/test.csv')  # Cargar el conjunto de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Rellenar valores faltantes\n",
    "def clean_data(df):\n",
    "    # Completar valores faltantes\n",
    "    df['Year'] = df['Year'].fillna(df['Year'].median())  # Completar con la mediana\n",
    "    df['Publisher'] = df['Publisher'].fillna('Unknown')  # Completar con \"Unknown\"\n",
    "\n",
    "    # Eliminar columnas irrelevantes\n",
    "    if 'Summary' in df.columns:\n",
    "        df = df.drop(columns=['Summary'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Paso 2: Convertir columnas numéricas con valores inconsistentes\n",
    "def convert_to_numeric(value):\n",
    "    \"\"\"\n",
    "    Convierte valores como '1.2K' en valores numéricos.\n",
    "    \"\"\"\n",
    "    value_str = str(value)\n",
    "    if 'K' in value_str:\n",
    "        return float(value_str.replace('K', '')) * 1000\n",
    "    try:\n",
    "        return float(value_str)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "# Paso 3: Manejar outliers\n",
    "def handle_outliers(df, columns):\n",
    "    \"\"\"\n",
    "    Aplica winsorización para manejar valores extremos en las columnas especificadas.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = winsorize(df[col], limits=[0.01, 0.01])  # Recorta 1% inferior y superior\n",
    "    return df\n",
    "\n",
    "# Paso 4: Codificar variables categóricas\n",
    "def encode_categorical(df, categorical_columns):\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in categorical_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = label_encoder.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "# Paso 5: Escalar columnas numéricas\n",
    "def scale_numerical(df, numerical_columns):\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "    return df\n",
    "\n",
    "# Paso 6: Rellenar valores faltantes en `Genre` usando `Summary`\n",
    "def fill_missing_genres(df):\n",
    "    \"\"\"\n",
    "    Rellena los valores faltantes de la columna `Genre` basándose en la columna `Summary`.\n",
    "    Utiliza un modelo de clasificación de texto.\n",
    "    \"\"\"\n",
    "    # Separar filas con y sin `Genre`\n",
    "    df_with_genre = df[df['Genre'].notnull()]\n",
    "    df_missing_genre = df[df['Genre'].isnull()]\n",
    "\n",
    "    if len(df_missing_genre) > 0:\n",
    "        # Convertir valores categóricos de `Genre` a números\n",
    "        label_encoder = LabelEncoder()\n",
    "        df_with_genre['Genre'] = label_encoder.fit_transform(df_with_genre['Genre'])\n",
    "\n",
    "        # Modelo de clasificación de texto\n",
    "        text_clf = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english', max_features=1000)),\n",
    "            ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "        ])\n",
    "\n",
    "        # Entrenar el modelo con los datos disponibles\n",
    "        text_clf.fit(df_with_genre['Summary'], df_with_genre['Genre'])\n",
    "\n",
    "        # Predecir los géneros faltantes\n",
    "        predicted_genres = text_clf.predict(df_missing_genre['Summary'])\n",
    "\n",
    "        # Convertir las predicciones de vuelta a etiquetas originales\n",
    "        df_missing_genre['Genre'] = label_encoder.inverse_transform(predicted_genres)\n",
    "\n",
    "        # Combinar las filas con `Genre` y las predichas\n",
    "        df = pd.concat([df_with_genre, df_missing_genre])\n",
    "\n",
    "# Paso 7: Crear nuevas columnas derivadas\n",
    "def create_new_columns(df):\n",
    "    \"\"\"\n",
    "    Crea nuevas columnas derivadas basadas en la información existente.\n",
    "    \"\"\"\n",
    "    df['Game_Age'] = 2024 - df['Year']\n",
    "    \n",
    "    # Ratios regionales\n",
    "    df['NorthAmerica_Global_Ratio'] = df['North America'] / df['Global']\n",
    "    df['Europe_Global_Ratio'] = df['Europe'] / df['Global']\n",
    "    df['Japan_Global_Ratio'] = df['Japan'] / df['Global']\n",
    "    df['RestOfWorld_Global_Ratio'] = df['Rest of World'] / df['Global']\n",
    "\n",
    "    # Relación entre reseñas y wishlist\n",
    "    df['Reviews_Wishlist_Ratio'] = df['Number of Reviews'] / df['Wishlist']\n",
    "\n",
    "    # Interacciones categóricas\n",
    "    df['Publisher_Platform_Interaction'] = df['Publisher'] + df['Platform']\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_with_genre_and_columns(df):\n",
    "    # Limpiar datos\n",
    "    df = clean_data(df)\n",
    "\n",
    "    # Rellenar valores faltantes en `Genre` usando `Summary`\n",
    "    if 'Summary' in df.columns and 'Genre' in df.columns:\n",
    "        df = fill_missing_genres(df)\n",
    "\n",
    "    # Convertir columnas numéricas con valores inconsistentes\n",
    "    columns_to_convert = ['Europe', 'Japan', 'Rest of World', 'North America', \n",
    "                          'Global', 'Number of Reviews', 'Wishlist']\n",
    "    for col in columns_to_convert:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(convert_to_numeric)\n",
    "\n",
    "    # Manejar outliers\n",
    "    outlier_columns = ['Global', 'Wishlist']\n",
    "    df = handle_outliers(df, outlier_columns)\n",
    "\n",
    "    # Codificar columnas categóricas\n",
    "    categorical_columns = ['Game Title', 'Publisher', 'Platform', 'Genre']\n",
    "    df = encode_categorical(df, categorical_columns)\n",
    "\n",
    "    # Crear nuevas columnas derivadas\n",
    "    df = create_new_columns(df)\n",
    "\n",
    "    # Escalar columnas numéricas\n",
    "    numerical_columns = ['North America', 'Europe', 'Japan', 'Rest of World', \n",
    "                         'Global', 'Number of Reviews', 'Wishlist', 'Game_Age', \n",
    "                         'Europe_Global_Ratio', 'Japan_Global_Ratio', \n",
    "                         'NorthAmerica_Global_Ratio', 'RestOfWorld_Global_Ratio',\n",
    "                         'Reviews_Wishlist_Ratio']\n",
    "    df = scale_numerical(df, numerical_columns)\n",
    "\n",
    "    # Eliminar columnas irrelevantes\n",
    "    columns_to_drop = ['Game Title']\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "    # Eliminar las columnas regionales originales después de crear los ratios\n",
    "    columns_to_drop = ['North America', 'Europe', 'Japan', 'Rest of World']\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Aplicar el preprocesamiento actualizado\n",
    "df_train = preprocess_data_with_genre_and_columns(df_train)\n",
    "df_test = preprocess_data_with_genre_and_columns(df_test)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(\"Datos preprocesados con géneros rellenados y nuevas columnas (train):\")\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar correlación con la variable objetivo (para regresión)\n",
    "def evaluate_feature_correlation(X, y):\n",
    "    \"\"\"\n",
    "    Evalúa la correlación de cada característica con la variable objetivo.\n",
    "    Devuelve un DataFrame con las puntuaciones.\n",
    "    \"\"\"\n",
    "    selector = SelectKBest(score_func=f_regression, k='all')\n",
    "    selector.fit(X, y)\n",
    "    scores = selector.scores_\n",
    "\n",
    "    # Crear un DataFrame con las puntuaciones\n",
    "    feature_scores = pd.DataFrame({'Feature': X.columns, 'Score': scores})\n",
    "    feature_scores = feature_scores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "    print(\"Importancia de características basada en correlación:\")\n",
    "    print(feature_scores)\n",
    "    return feature_scores\n",
    "\n",
    "# Función para evaluar la importancia de características usando un modelo\n",
    "def evaluate_feature_importance_model(X, y):\n",
    "    \"\"\"\n",
    "    Evalúa la importancia de características utilizando un RandomForestRegressor.\n",
    "    Devuelve un DataFrame con las importancias.\n",
    "    \"\"\"\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X, y)\n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    # Crear un DataFrame con las importancias\n",
    "    feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "    feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Visualizar la importancia de características\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importances['Feature'], feature_importances['Importance'])\n",
    "    plt.xlabel(\"Importancia\")\n",
    "    plt.ylabel(\"Características\")\n",
    "    plt.title(\"Importancia de características según RandomForest\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Importancia de características basada en RandomForest:\")\n",
    "    print(feature_importances)\n",
    "    return feature_importances\n",
    "\n",
    "# Selección de las características más relevantes\n",
    "def select_top_features(X, y, k=10):\n",
    "    \"\"\"\n",
    "    Selecciona las k características más relevantes utilizando SelectKBest.\n",
    "    \"\"\"\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "    # Obtener las columnas seleccionadas\n",
    "    selected_columns = X.columns[selector.get_support()]\n",
    "    print(f\"Características seleccionadas ({k} mejores): {selected_columns}\")\n",
    "    return X_selected, selected_columns\n",
    "\n",
    "# Para df_train (como ya tienes)\n",
    "X_train = df_train.drop(columns=['Rating'])  # Variables predictoras\n",
    "y_train = df_train['Rating']  # Variable objetivo\n",
    "\n",
    "# Evaluar y seleccionar características en df_train\n",
    "correlation_scores = evaluate_feature_correlation(X_train, y_train)\n",
    "importance_scores = evaluate_feature_importance_model(X_train, y_train)\n",
    "X_train_selected, selected_columns = select_top_features(X_train, y_train, k=10)\n",
    "\n",
    "# Actualizar el dataset de entrenamiento\n",
    "df_train_selected = pd.DataFrame(X_train_selected, columns=selected_columns)\n",
    "df_train_selected['Rating'] = y_train  # Añadir la columna objetivo para usar en el modelo\n",
    "\n",
    "# Aplicar la misma selección de características al conjunto de prueba**\n",
    "if 'Rating' in df_test.columns:\n",
    "    X_test = df_test.drop(columns=['Rating'])  # Variables predictoras en el conjunto de prueba\n",
    "    y_test = df_test['Rating']  # Variable objetivo en el conjunto de prueba\n",
    "else:\n",
    "    X_test = df_test\n",
    "    y_test = None\n",
    "\n",
    "# Seleccionar las mismas características en df_test usando `selected_columns`\n",
    "X_test_selected = X_test[selected_columns]\n",
    "\n",
    "# Actualizar el dataset de prueba\n",
    "df_test_selected = pd.DataFrame(X_test_selected, columns=selected_columns)\n",
    "if y_test is not None:\n",
    "    df_test_selected['Rating'] = y_test  # Solo si `Rating` está disponible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceso de nuevo los datos eliminando columnas irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_optimized(df):\n",
    "\n",
    "    # Eliminar columnas menos relevantes\n",
    "    columns_to_drop = ['id', 'Publisher_Platform_Interaction', 'Publisher', 'Wishlist', \n",
    "                       'Number of Reviews', 'Reviews_Wishlist_Ratio']\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Aplicar el preprocesamiento optimizado\n",
    "df_train = preprocess_data_optimized(df_train)\n",
    "df_test = preprocess_data_optimized(df_test)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(\"Datos preprocesados optimizados (train):\")\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar correlación con la variable objetivo (para regresión)\n",
    "def evaluate_feature_correlation(X, y):\n",
    "    \"\"\"\n",
    "    Evalúa la correlación de cada característica con la variable objetivo.\n",
    "    Devuelve un DataFrame con las puntuaciones.\n",
    "    \"\"\"\n",
    "    selector = SelectKBest(score_func=f_regression, k='all')\n",
    "    selector.fit(X, y)\n",
    "    scores = selector.scores_\n",
    "\n",
    "    # Crear un DataFrame con las puntuaciones\n",
    "    feature_scores = pd.DataFrame({'Feature': X.columns, 'Score': scores})\n",
    "    feature_scores = feature_scores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "    print(\"Importancia de características basada en correlación:\")\n",
    "    print(feature_scores)\n",
    "    return feature_scores\n",
    "\n",
    "# Función para evaluar la importancia de características usando un modelo\n",
    "def evaluate_feature_importance_model(X, y):\n",
    "    \"\"\"\n",
    "    Evalúa la importancia de características utilizando un RandomForestRegressor.\n",
    "    Devuelve un DataFrame con las importancias.\n",
    "    \"\"\"\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X, y)\n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    # Crear un DataFrame con las importancias\n",
    "    feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "    feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Visualizar la importancia de características\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importances['Feature'], feature_importances['Importance'])\n",
    "    plt.xlabel(\"Importancia\")\n",
    "    plt.ylabel(\"Características\")\n",
    "    plt.title(\"Importancia de características según RandomForest\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Importancia de características basada en RandomForest:\")\n",
    "    print(feature_importances)\n",
    "    return feature_importances\n",
    "\n",
    "# Selección de las características más relevantes\n",
    "def select_top_features(X, y, k=10):\n",
    "    \"\"\"\n",
    "    Selecciona las k características más relevantes utilizando SelectKBest.\n",
    "    \"\"\"\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "    # Obtener las columnas seleccionadas\n",
    "    selected_columns = X.columns[selector.get_support()]\n",
    "    print(f\"Características seleccionadas ({k} mejores): {selected_columns}\")\n",
    "    return X_selected, selected_columns\n",
    "\n",
    "# Para df_train (como ya tienes)\n",
    "X_train = df_train.drop(columns=['Rating'])  # Variables predictoras\n",
    "y_train = df_train['Rating']  # Variable objetivo\n",
    "\n",
    "# Evaluar y seleccionar características en df_train\n",
    "correlation_scores = evaluate_feature_correlation(X_train, y_train)\n",
    "importance_scores = evaluate_feature_importance_model(X_train, y_train)\n",
    "X_train_selected, selected_columns = select_top_features(X_train, y_train, k=10)\n",
    "\n",
    "# Actualizar el dataset de entrenamiento\n",
    "df_train_selected = pd.DataFrame(X_train_selected, columns=selected_columns)\n",
    "df_train_selected['Rating'] = y_train  # Añadir la columna objetivo para usar en el modelo\n",
    "\n",
    "# Aplicar la misma selección de características al conjunto de prueba\n",
    "# Como no tiene la columna `Rating`, simplemente seleccionamos las columnas relevantes\n",
    "X_test = df_test[selected_columns]\n",
    "\n",
    "# Actualizar el dataset de prueba\n",
    "df_test_selected = pd.DataFrame(X_test, columns=selected_columns)\n",
    "\n",
    "# df_test_selected ahora contiene solo las características seleccionadas para hacer predicciones\n",
    "print(\"Características seleccionadas en el conjunto de prueba:\")\n",
    "print(df_test_selected.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Division de datos procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos para entrenamiento y prueba\n",
    "\n",
    "# Entrenamiento: X_train y y_train\n",
    "X_train = df_train_selected.drop(columns=['Rating'])  # Variables predictoras del conjunto de entrenamiento\n",
    "y_train = df_train_selected['Rating']  # Variable objetivo del conjunto de entrenamiento\n",
    "\n",
    "# Prueba: X_test (sin Rating)\n",
    "X_test = df_test_selected  # df_test seleccionado y procesado ya no incluye la columna Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(estimator, param_grid, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Entrena un modelo con los hiperparámetros especificados utilizando GridSearchCV.\n",
    "    \"\"\"\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo entrenado y genera las métricas y predicciones.\n",
    "    \"\"\"\n",
    "    # Validación cruzada en el conjunto de entrenamiento\n",
    "    cv_scores_mse = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_mean_mse = -cv_scores_mse.mean()\n",
    "    cv_std_mse = cv_scores_mse.std()\n",
    "    cv_rmse = sqrt(cv_mean_mse)\n",
    "    mae = mean_absolute_error(y_train, model.predict(X_train))  # MAE en el conjunto de entrenamiento\n",
    "    median_ae = median_absolute_error(y_train, model.predict(X_train))  # Mediana del error absoluto\n",
    "    r2 = r2_score(y_train, model.predict(X_train))  # R² en el conjunto de entrenamiento\n",
    "    max_error_value = max_error(y_train, model.predict(X_train))  # Máximo error absoluto\n",
    "\n",
    "    print(\"\\nValidación cruzada:\")\n",
    "    print(f\"MSE promedio (CV): {cv_mean_mse:.4f}\")\n",
    "    print(f\"RMSE promedio (CV): {cv_rmse:.4f}\")\n",
    "    print(f\"Desviación estándar (MSE): {cv_std_mse:.4f}\")\n",
    "\n",
    "    # Generar predicciones para el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        'cv_mean_mse': cv_mean_mse,\n",
    "        'cv_std_mse': cv_std_mse,\n",
    "        'cv_rmse': cv_rmse,\n",
    "        'mae': mae,\n",
    "        'median_ae': median_ae,\n",
    "        'r2': r2,\n",
    "        'max_error': max_error_value\n",
    "    }\n",
    "    return y_pred, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar resultados\n",
    "def generate_results(y_pred, metrics, model_name, hyperparameters):\n",
    "    \"\"\"\n",
    "    Genera las carpetas, archivos de predicciones y métricas.\n",
    "    \"\"\"\n",
    "    # Crear carpetas base para resultados\n",
    "    os.makedirs(f\"predictions/{model_name}\", exist_ok=True)\n",
    "    os.makedirs(f\"metrics/{model_name}\", exist_ok=True)\n",
    "    os.makedirs(\"metrics/MejoresModelos\", exist_ok=True)\n",
    "\n",
    "    # Guardar predicciones\n",
    "    file_suffix = \"_\".join([f\"{key}_{value}\" for key, value in hyperparameters.items()])\n",
    "    predictions_file = f\"predictions/{model_name}/predicciones_{file_suffix}.csv\"\n",
    "    pd.DataFrame({\n",
    "        \"id\": range(1, len(y_pred) + 1),  # Comenzar desde 1\n",
    "        \"predictions\": y_pred\n",
    "    }).to_csv(predictions_file, index=False)\n",
    "    print(f\"Predicciones guardadas en {predictions_file}\")\n",
    "\n",
    "    # Guardar métricas\n",
    "    metrics_file = f\"metrics/{model_name}/metrics_{file_suffix}.csv\"\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        f.write(\"Métrica,Valor\\n\")\n",
    "        f.write(f\"MSE promedio (CV),{metrics['cv_mean_mse']:.4f}\\n\")\n",
    "        f.write(f\"RMSE promedio (CV),{metrics['cv_rmse']:.4f}\\n\")\n",
    "        f.write(f\"Desviación estándar (MSE),{metrics['cv_std_mse']:.4f}\\n\")\n",
    "        f.write(f\"MAE promedio (CV),{metrics['mae']:.4f}\\n\")\n",
    "        f.write(f\"Mediana del Error Absoluto (MedianAE),{metrics['median_ae']:.4f}\\n\")\n",
    "        f.write(f\"R² (CV),{metrics['r2']:.4f}\\n\")\n",
    "        f.write(f\"Max Error (CV),{metrics['max_error']:.4f}\\n\")\n",
    "    print(f\"Métricas guardadas en {metrics_file}\")\n",
    "\n",
    "    return predictions_file, metrics_file\n",
    "\n",
    "# Guarda el modelo con mejores metricas\n",
    "def save_best_model_metrics(best_model, model_name, best_metrics, hyperparameters):\n",
    "    \"\"\"\n",
    "    Guarda las métricas del mejor modelo en la carpeta MejoresModelos.\n",
    "    \"\"\"\n",
    "    os.makedirs(\"metrics/MejoresModelos\", exist_ok=True)\n",
    "\n",
    "    # Crear un archivo con las métricas del mejor modelo\n",
    "    file_suffix = \"_\".join([f\"{key}_{value}\" for key, value in hyperparameters.items()])\n",
    "    best_metrics_file = f\"metrics/MejoresModelos/{model_name}_mejor_modelo_metrics.csv\"\n",
    "\n",
    "    with open(best_metrics_file, \"w\") as f:\n",
    "        f.write(\"Métrica,Valor\\n\")\n",
    "        f.write(f\"MSE promedio (CV),{best_metrics['cv_mean_mse']:.4f}\\n\")\n",
    "        f.write(f\"RMSE promedio (CV),{best_metrics['cv_rmse']:.4f}\\n\")\n",
    "        f.write(f\"Desviación estándar (MSE),{best_metrics['cv_std_mse']:.4f}\\n\")\n",
    "        f.write(f\"MAE promedio (CV),{best_metrics['mae']:.4f}\\n\")\n",
    "        f.write(f\"Mediana del Error Absoluto (MedianAE),{best_metrics['median_ae']:.4f}\\n\")\n",
    "        f.write(f\"R² (CV),{best_metrics['r2']:.4f}\\n\")\n",
    "        f.write(f\"Max Error (CV),{best_metrics['max_error']:.4f}\\n\")\n",
    "    print(f\"Métricas del mejor modelo guardadas en {best_metrics_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flujo Principal y Ejecucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"OBL-Machine-Learning-2024\",\n",
    "    name=\"Evaluación_Modelos\",\n",
    "    config={\"task\": \"Regresión\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_rf(X_train, y_train, X_test):\n",
    "    # Inicializar un nuevo experimento en WandB\n",
    "    wandb.init(project=\"OBL-Machine-Learning-2024\", name=\"RandomForest\", config={\"task\": \"Regression\"})\n",
    "\n",
    "    results = []\n",
    "    n_estimators_values = [50, 100, 200]\n",
    "    max_depth_values = [10, 20, None]\n",
    "    max_features = ['sqrt']  # sqrt es recomendado para datasets grandes\n",
    "    min_samples_split = [2, 5, 10]  # Controla el mínimo de datos requeridos para dividir un nodo\n",
    "\n",
    "    for n_estimators in n_estimators_values:\n",
    "        for max_depth in max_depth_values:\n",
    "            # Entrenamiento\n",
    "            param_grid = {\n",
    "                'n_estimators': [n_estimators],\n",
    "                'max_depth': [max_depth],\n",
    "                'max_features': max_features,\n",
    "                'min_samples_split': min_samples_split\n",
    "            }\n",
    "            model = train_model(RandomForestRegressor(random_state=42), param_grid, X_train, y_train)\n",
    "\n",
    "            # Evaluación\n",
    "            y_pred, metrics = evaluate_model(model, X_train, y_train, X_test)\n",
    "\n",
    "            # Generar resultados\n",
    "            hyperparameters = {\"n_estimators\": n_estimators, \"max_depth\": max_depth}\n",
    "            predictions_file, metrics_file = generate_results(y_pred, metrics, \"RandomForest\", hyperparameters)\n",
    "\n",
    "            # Guardar resultados intermedios\n",
    "            results.append((n_estimators, max_depth, metrics['cv_mean_mse'], metrics['cv_std_mse'], \n",
    "                            predictions_file, metrics_file, model, metrics))\n",
    "\n",
    "    # Seleccionar el mejor modelo basado en MSE promedio\n",
    "    best_model = min(results, key=lambda x: x[2])  # x[2] es `cv_mean_mse`\n",
    "\n",
    "    print(\"\\nMejor modelo:\")\n",
    "    print(f\"- Número de árboles (n_estimators): {best_model[0]}\")\n",
    "    print(f\"- Profundidad máxima (max_depth): {best_model[1]}\")\n",
    "    print(f\"- MSE promedio (CV): {best_model[2]:.4f}\")\n",
    "    print(f\"- Desviación estándar del MSE (CV): {best_model[3]:.4f}\")\n",
    "    print(f\"- MAE (Conjunto de prueba): {best_model[7]['mae']:.4f}\")\n",
    "    print(f\"- R² (Conjunto de prueba): {best_model[7]['r2']:.4f}\")\n",
    "    print(f\"- RMSE (Conjunto de prueba): {best_model[7]['cv_rmse']:.4f}\")\n",
    "\n",
    "    # Guardar métricas del mejor modelo\n",
    "    hyperparameters = {\"n_estimators\": best_model[0], \"max_depth\": best_model[1]}\n",
    "    save_best_model_metrics(best_model, \"RandomForest\", best_model[7], hyperparameters)\n",
    "\n",
    "    # Registrar el mejor modelo en WandB\n",
    "    wandb.log({\n",
    "        \"Mejor MSE promedio (CV)\": best_model[2],\n",
    "        \"Mejor Desviación estándar (CV)\": best_model[3],\n",
    "        \"Mejor RMSE (CV)\": best_model[7]['cv_rmse'],\n",
    "        \"Mejor MAE\": best_model[7]['mae'],\n",
    "        \"Mejor R²\": best_model[7]['r2']\n",
    "    })\n",
    "\n",
    "    '''\n",
    "    # Crear una tabla con los resultados numéricos del mejor modelo\n",
    "    table_data = [\n",
    "        [best_model[2],  # MSE promedio (CV)\n",
    "         best_model[3],  # Desviación estándar (CV)\n",
    "         best_model[7]['mae'],  # MAE\n",
    "         best_model[7]['r2'],  # R²\n",
    "         best_model[7]['cv_rmse']]  # RMSE\n",
    "    ]\n",
    "    table_columns = [\"MSE promedio (CV)\", \"Desviación estándar (CV)\", \"MAE\", \"R²\", \"RMSE\"]\n",
    "    wandb.log({\"Mejor Modelo\": wandb.Table(data=table_data, columns=table_columns)})\n",
    "    '''\n",
    "    # Finalizar el experimento en WandB\n",
    "    wandb.finish()\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Llamar a la función principal\n",
    "best_model_rf = main_rf(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb  # Asegúrate de importar WandB\n",
    "\n",
    "def main_gb(X_train, y_train, X_test):\n",
    "    # Inicializar un nuevo experimento en WandB\n",
    "    wandb.init(project=\"OBL-Machine-Learning-2024\", name=\"GradientBoosting\", config={\"task\": \"Regression\"})\n",
    "\n",
    "    results = []\n",
    "    n_estimators_values = [100, 200]\n",
    "    learning_rate_values = [0.1, 0.2]\n",
    "    max_depth_values = [3, 5, 10]\n",
    "    subsample_values = [0.8, 1.0]  # Fracción de muestras utilizadas para ajustar los árboles\n",
    "\n",
    "    for n_estimators in n_estimators_values:\n",
    "        for learning_rate in learning_rate_values:\n",
    "            # Entrenamiento\n",
    "            param_grid = {\n",
    "                'n_estimators': [n_estimators],\n",
    "                'learning_rate': [learning_rate],\n",
    "                'max_depth': max_depth_values,\n",
    "                'subsample': subsample_values\n",
    "            }\n",
    "            model = train_model(GradientBoostingRegressor(random_state=42), param_grid, X_train, y_train)\n",
    "\n",
    "            # Evaluación\n",
    "            y_pred, metrics = evaluate_model(model, X_train, y_train, X_test)\n",
    "\n",
    "            # Generar resultados\n",
    "            hyperparameters = {\"n_estimators\": n_estimators, \"learning_rate\": learning_rate}\n",
    "            predictions_file, metrics_file = generate_results(y_pred, metrics, \"GradientBoosting\", hyperparameters)\n",
    "\n",
    "            # Guardar resultados intermedios\n",
    "            results.append((n_estimators, learning_rate, metrics['cv_mean_mse'], metrics['cv_std_mse'], \n",
    "                            predictions_file, metrics_file, model, metrics))\n",
    "\n",
    "    # Seleccionar el mejor modelo basado en MSE promedio\n",
    "    best_model = min(results, key=lambda x: x[2])  # x[2] es `cv_mean_mse`\n",
    "    print(\"\\nMejor modelo:\")\n",
    "    print(f\"- Número de estimadores (n_estimators): {best_model[0]}\")\n",
    "    print(f\"- Tasa de aprendizaje (learning_rate): {best_model[1]}\")\n",
    "    print(f\"- MSE promedio (CV): {best_model[2]:.4f}\")\n",
    "    print(f\"- Desviación estándar del MSE (CV): {best_model[3]:.4f}\")\n",
    "    print(f\"- MAE (Conjunto de prueba): {best_model[7]['mae']:.4f}\")\n",
    "    print(f\"- R² (Conjunto de prueba): {best_model[7]['r2']:.4f}\")\n",
    "    print(f\"- RMSE (Conjunto de prueba): {best_model[7]['cv_rmse']:.4f}\")\n",
    "\n",
    "    # Guardar métricas del mejor modelo\n",
    "    hyperparameters = {\"n_estimators\": best_model[0], \"learning_rate\": best_model[1]}\n",
    "    save_best_model_metrics(best_model, \"GradientBoosting\", best_model[7], hyperparameters)\n",
    "\n",
    "    # Registrar el mejor modelo en WandB\n",
    "    wandb.log({\n",
    "        \"Mejor MSE promedio (CV)\": best_model[2],\n",
    "        \"Mejor Desviación estándar (CV)\": best_model[3],\n",
    "        \"Mejor RMSE (CV)\": best_model[7]['cv_rmse'],\n",
    "        \"Mejor MAE\": best_model[7]['mae'],\n",
    "        \"Mejor R²\": best_model[7]['r2']\n",
    "    })\n",
    "\n",
    "    '''\n",
    "    # Crear una tabla con los resultados numéricos del mejor modelo\n",
    "    table_data = [\n",
    "        [best_model[2],  # MSE promedio (CV)\n",
    "         best_model[3],  # Desviación estándar (CV)\n",
    "         best_model[7]['mae'],  # MAE\n",
    "         best_model[7]['r2'],  # R²\n",
    "         best_model[7]['cv_rmse']]  # RMSE\n",
    "    ]\n",
    "    table_columns = [\"MSE promedio (CV)\", \"Desviación estándar (CV)\", \"MAE\", \"R²\", \"RMSE\"]\n",
    "    wandb.log({\"Mejor Modelo\": wandb.Table(data=table_data, columns=table_columns)})\n",
    "    '''\n",
    "    \n",
    "    # Finalizar el experimento en WandB\n",
    "    wandb.finish()\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Llamar a la función principal\n",
    "best_model_gb = main_gb(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_ada(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Entrena, evalúa y guarda resultados para el modelo AdaBoost.\n",
    "    \"\"\"\n",
    "\n",
    "    # Inicializar un nuevo experimento en WandB\n",
    "    wandb.init(project=\"OBL-Machine-Learning-2024\", name=\"AdaBoost\", config={\"task\": \"Regression\"})\n",
    "    \n",
    "    results = []\n",
    "    n_estimators_values = [50, 100]\n",
    "    learning_rate_values = [0.1, 0.2, 0.5]\n",
    "\n",
    "    for n_estimators in n_estimators_values:\n",
    "        for learning_rate in learning_rate_values:\n",
    "            # Configuración de hiperparámetros específicos de AdaBoost\n",
    "            param_grid = {\n",
    "                'n_estimators': [n_estimators],\n",
    "                'learning_rate': [learning_rate],\n",
    "                'estimator__max_depth': [5, 7, 10],  # Este hiperparámetro no cambiará\n",
    "                'loss': ['linear', 'square', 'exponential']\n",
    "            }\n",
    "\n",
    "            # Crear el modelo base de AdaBoost con DecisionTreeRegressor\n",
    "            base_estimator = DecisionTreeRegressor(random_state=42)\n",
    "            model = AdaBoostRegressor(estimator=base_estimator, random_state=42)\n",
    "\n",
    "            # Entrenamiento\n",
    "            trained_model = train_model(model, param_grid, X_train, y_train)\n",
    "\n",
    "            # Evaluación\n",
    "            y_pred, metrics = evaluate_model(trained_model, X_train, y_train, X_test)\n",
    "\n",
    "            # Generar resultados\n",
    "            hyperparameters = {\"n_estimators\": n_estimators, \"learning_rate\": learning_rate}\n",
    "            predictions_file, metrics_file = generate_results(y_pred, metrics, \"AdaBoost\", hyperparameters)\n",
    "\n",
    "            # Guardar resultados intermedios\n",
    "            results.append((n_estimators, learning_rate, metrics['cv_mean_mse'], metrics['cv_std_mse'], \n",
    "                            predictions_file, metrics_file, trained_model, metrics))\n",
    "\n",
    "    # Seleccionar el mejor modelo basado en MSE promedio\n",
    "    best_model = min(results, key=lambda x: x[2])  # x[2] es `cv_mean_mse`\n",
    "    print(\"\\nMejor modelo:\")\n",
    "    print(f\"- Número de estimadores (n_estimators): {best_model[0]}\")\n",
    "    print(f\"- Tasa de aprendizaje (learning_rate): {best_model[1]}\")\n",
    "    print(f\"- MSE promedio (CV): {best_model[2]:.4f}\")\n",
    "    print(f\"- Desviación estándar del MSE (CV): {best_model[3]:.4f}\")\n",
    "    print(f\"- MAE (Conjunto de prueba): {best_model[7]['mae']:.4f}\")\n",
    "    print(f\"- R² (Conjunto de prueba): {best_model[7]['r2']:.4f}\")\n",
    "    print(f\"- RMSE (Conjunto de prueba): {best_model[7]['cv_rmse']:.4f}\")\n",
    "\n",
    "    # Guardar métricas del mejor modelo\n",
    "    hyperparameters = {\"n_estimators\": best_model[0], \"learning_rate\": best_model[1]}\n",
    "    save_best_model_metrics(best_model, \"AdaBoost\", best_model[7], hyperparameters)\n",
    "\n",
    "    # Registrar el mejor modelo en WandB\n",
    "    wandb.log({\n",
    "        \"Mejor MSE promedio (CV)\": best_model[2],\n",
    "        \"Mejor Desviación estándar (CV)\": best_model[3],\n",
    "        \"Mejor RMSE (CV)\": best_model[7]['cv_rmse'],\n",
    "        \"Mejor MAE\": best_model[7]['mae'],\n",
    "        \"Mejor R²\": best_model[7]['r2']\n",
    "    })\n",
    "\n",
    "    '''\n",
    "    #Crear una tabla con los resultados numéricos del mejor modelo\n",
    "    table_data = [\n",
    "        [best_model[2],  # MSE promedio (CV)\n",
    "         best_model[3],  # Desviación estándar (CV)\n",
    "         best_model[7]['mae'],  # MAE\n",
    "         best_model[7]['r2'],  # R²\n",
    "         best_model[7]['cv_rmse']]  # RMSE\n",
    "    ]\n",
    "    table_columns = [\"MSE promedio (CV)\", \"Desviación estándar (CV)\", \"MAE\", \"R²\", \"RMSE\"]\n",
    "    wandb.log({\"Mejor Modelo\": wandb.Table(data=table_data, columns=table_columns)})\n",
    "    '''\n",
    "\n",
    "    # Finalizar el experimento en WandB\n",
    "    wandb.finish()\n",
    "\n",
    "    return best_model\n",
    "\n",
    "best_model_ada = main_ada(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_tree(X_train, y_train, X_test):\n",
    "\n",
    "    # Inicializar un nuevo experimento en WandB\n",
    "    wandb.init(project=\"OBL-Machine-Learning-2024\", name=\"ArbolesDeDecision\", config={\"task\": \"Regression\"})\n",
    "\n",
    "    results = []\n",
    "    max_depth_values = [3, 5, 10, None]\n",
    "    criterion_values = ['squared_error', 'absolute_error']\n",
    "    max_features_values = ['sqrt', 'log2']\n",
    "\n",
    "    for max_depth in max_depth_values:\n",
    "        for criterion in criterion_values:\n",
    "            for max_features in max_features_values:\n",
    "                param_grid = {\n",
    "                    'max_depth': [max_depth],\n",
    "                    'criterion': [criterion],\n",
    "                    'max_features': [max_features],\n",
    "                    'min_samples_leaf': [1, 5, 10],\n",
    "                    'splitter': ['best']\n",
    "                }\n",
    "\n",
    "                # Entrenamiento\n",
    "                model = train_model(DecisionTreeRegressor(random_state=42), param_grid, X_train, y_train)\n",
    "\n",
    "                # Evaluación\n",
    "                y_pred, metrics = evaluate_model(model, X_train, y_train, X_test)\n",
    "\n",
    "                # Generar resultados\n",
    "                hyperparameters = {\"max_depth\": max_depth, \"criterion\": criterion, \"max_features\": max_features}\n",
    "                predictions_file, metrics_file = generate_results(y_pred, metrics, \"ArbolesDeDecision\", hyperparameters)\n",
    "\n",
    "                # Guardar resultados intermedios\n",
    "                results.append((max_depth, criterion, max_features, metrics['cv_mean_mse'], metrics['cv_std_mse'], \n",
    "                                predictions_file, metrics_file, metrics))\n",
    "\n",
    "    # Seleccionar el mejor modelo basado en MSE promedio\n",
    "    best_model = min(results, key=lambda x: x[3])  # x[3] es `cv_mean_mse`\n",
    "    print(\"\\nMejor modelo:\")\n",
    "    print(f\"- Profundidad máxima (max_depth): {best_model[0]}\")\n",
    "    print(f\"- Criterio de división (criterion): {best_model[1]}\")\n",
    "    print(f\"- Máximas características (max_features): {best_model[2]}\")\n",
    "    print(f\"- MSE promedio (CV): {best_model[3]:.4f}\")\n",
    "    print(f\"- Desviación estándar del MSE (CV): {best_model[4]:.4f}\")\n",
    "    print(f\"- MAE (Conjunto de prueba): {best_model[7]['mae']:.4f}\")\n",
    "    print(f\"- R² (Conjunto de prueba): {best_model[7]['r2']:.4f}\")\n",
    "    print(f\"- RMSE (Conjunto de prueba): {best_model[7]['cv_rmse']:.4f}\")\n",
    "\n",
    "    # Registrar el mejor modelo en WandB\n",
    "    wandb.log({\n",
    "        \"Mejor MSE promedio (CV)\": best_model[2],\n",
    "        \"Mejor Desviación estándar (CV)\": best_model[3],\n",
    "        \"Mejor RMSE (CV)\": best_model[7]['cv_rmse'],\n",
    "        \"Mejor MAE\": best_model[7]['mae'],\n",
    "        \"Mejor R²\": best_model[7]['r2']\n",
    "    })\n",
    "\n",
    "    '''\n",
    "    #Crear una tabla con los resultados numéricos del mejor modelo\n",
    "    table_data = [\n",
    "        [best_model[2],  # MSE promedio (CV)\n",
    "         best_model[3],  # Desviación estándar (CV)\n",
    "         best_model[7]['mae'],  # MAE\n",
    "         best_model[7]['r2'],  # R²\n",
    "         best_model[7]['cv_rmse']]  # RMSE\n",
    "    ]\n",
    "    table_columns = [\"MSE promedio (CV)\", \"Desviación estándar (CV)\", \"MAE\", \"R²\", \"RMSE\"]\n",
    "    wandb.log({\"Mejor Modelo\": wandb.Table(data=table_data, columns=table_columns)})\n",
    "    '''\n",
    "\n",
    "    # Finalizar el experimento en WandB\n",
    "    wandb.finish()\n",
    "\n",
    "    # Guardar métricas del mejor modelo\n",
    "    hyperparameters = {\"max_depth\": best_model[0], \"criterion\": best_model[1], \"max_features\": best_model[2]}\n",
    "    save_best_model_metrics(best_model, \"ArbolesDeDecision\", best_model[7], hyperparameters)\n",
    "\n",
    "    return best_model\n",
    "\n",
    "best_model_tree = main_tree(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_nn(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Proceso principal para entrenar y evaluar Redes Neuronales.\n",
    "    \"\"\"\n",
    "\n",
    "    # Inicializar un nuevo experimento en WandB\n",
    "    wandb.init(project=\"OBL-Machine-Learning-2024\", name=\"RedesNeuronales\", config={\"task\": \"Regression\"})\n",
    "\n",
    "    results = []\n",
    "    hidden_layer_sizes_values = [(50,), (100,), (100, 50)]\n",
    "    learning_rate_values = [0.001, 0.01]\n",
    "\n",
    "    for hidden_layer_sizes in hidden_layer_sizes_values:\n",
    "        for learning_rate_init in learning_rate_values:\n",
    "            # Configuración del grid para Redes Neuronales\n",
    "            param_grid = {\n",
    "                'hidden_layer_sizes': [hidden_layer_sizes],\n",
    "                'activation': ['relu'],  # Fijo\n",
    "                'alpha': [0.0001, 0.001],  # Regularización fija\n",
    "                'learning_rate_init': [learning_rate_init],\n",
    "                'max_iter': [200, 300]\n",
    "            }\n",
    "\n",
    "            # Entrenar el modelo\n",
    "            model = train_model(MLPRegressor(random_state=42), param_grid, X_train, y_train)\n",
    "\n",
    "            # Evaluar el modelo\n",
    "            y_pred, metrics = evaluate_model(model, X_train, y_train, X_test)\n",
    "\n",
    "            # Generar resultados\n",
    "            hyperparameters = {\"hidden_layer_sizes\": hidden_layer_sizes, \"learning_rate_init\": learning_rate_init}\n",
    "            predictions_file, metrics_file = generate_results(y_pred, metrics, \"RedesNeuronales\", hyperparameters)\n",
    "\n",
    "            # Guardar resultados intermedios\n",
    "            results.append((hidden_layer_sizes, learning_rate_init, metrics['cv_mean_mse'], metrics['cv_std_mse'], \n",
    "                            predictions_file, metrics_file, metrics))\n",
    "\n",
    "    # Seleccionar el mejor modelo basado en MSE promedio\n",
    "    best_model = min(results, key=lambda x: x[2])  # x[2] es `cv_mean_mse`\n",
    "    print(\"\\nMejor modelo:\")\n",
    "    print(f\"- Arquitectura oculta (hidden_layer_sizes): {best_model[0]}\")\n",
    "    print(f\"- Tasa de aprendizaje (learning_rate_init): {best_model[1]}\")\n",
    "    print(f\"- MSE promedio (CV): {best_model[2]:.4f}\")\n",
    "    print(f\"- Desviación estándar del MSE (CV): {best_model[3]:.4f}\")\n",
    "    print(f\"- MAE (Conjunto de prueba): {best_model[6]['mae']:.4f}\")\n",
    "    print(f\"- R² (Conjunto de prueba): {best_model[6]['r2']:.4f}\")\n",
    "    print(f\"- RMSE (Conjunto de prueba): {best_model[6]['cv_rmse']:.4f}\")\n",
    "\n",
    "    # Guardar las métricas del mejor modelo\n",
    "    hyperparameters = {\"hidden_layer_sizes\": best_model[0], \"learning_rate_init\": best_model[1]}\n",
    "    save_best_model_metrics(best_model, \"RedesNeuronales\", best_model[6], hyperparameters)\n",
    "\n",
    "    # Registrar el mejor modelo en WandB\n",
    "    wandb.log({\n",
    "        \"Mejor MSE promedio (CV)\": best_model[2],\n",
    "        \"Mejor Desviación estándar (CV)\": best_model[3],\n",
    "        \"Mejor RMSE (CV)\": best_model[6]['cv_rmse'],\n",
    "        \"Mejor MAE\": best_model[6]['mae'],\n",
    "        \"Mejor R²\": best_model[6]['r2']\n",
    "    })\n",
    "\n",
    "    '''\n",
    "    # Crear una tabla con los resultados numéricos del mejor modelo\n",
    "    table_data = [\n",
    "        [best_model[2],  # MSE promedio (CV)\n",
    "         best_model[3],  # Desviación estándar (CV)\n",
    "         best_model[6]['mae'],  # MAE\n",
    "         best_model[6]['r2'],  # R²\n",
    "         best_model[6]['cv_rmse']]  # RMSE\n",
    "    ]\n",
    "    table_columns = [\"MSE promedio (CV)\", \"Desviación estándar (CV)\", \"MAE\", \"R²\", \"RMSE\"]\n",
    "    wandb.log({\"Mejor Modelo\": wandb.Table(data=table_data, columns=table_columns)})\n",
    "    '''\n",
    "\n",
    "    # Finalizar el experimento en WandB\n",
    "    wandb.finish()\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Llamar al proceso principal\n",
    "best_model_nn = main_nn(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresion Lineal con Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_ridge(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Proceso principal para entrenar y evaluar Ridge Regression.\n",
    "    \"\"\"\n",
    "\n",
    "    # Inicializar un nuevo experimento en WandB\n",
    "    wandb.init(project=\"OBL-Machine-Learning-2024\", name=\"RidgeRegression\", config={\"task\": \"Regression\"})\n",
    "\n",
    "    results = []\n",
    "    alpha_values = [0.1, 1, 10, 100]\n",
    "    fit_intercept_values = [True, False]\n",
    "\n",
    "    for alpha in alpha_values:\n",
    "        for fit_intercept in fit_intercept_values:\n",
    "            # Configuración de hiperparámetros\n",
    "            param_grid = {'alpha': [alpha], 'fit_intercept': [fit_intercept]}\n",
    "\n",
    "            # Entrenar el modelo\n",
    "            model = train_model(Ridge(), param_grid, X_train, y_train)\n",
    "\n",
    "            # Evaluar el modelo\n",
    "            y_pred, metrics = evaluate_model(model, X_train, y_train, X_test)\n",
    "\n",
    "            # Guardar resultados\n",
    "            hyperparameters = {\"alpha\": alpha, \"fit_intercept\": fit_intercept}\n",
    "            predictions_file, metrics_file = generate_results(y_pred, metrics, \"RidgeRegression\", hyperparameters)\n",
    "\n",
    "            # Guardar resultados intermedios\n",
    "            results.append((alpha, fit_intercept, metrics['cv_mean_mse'], metrics['cv_std_mse'], \n",
    "                            predictions_file, metrics_file, metrics))\n",
    "\n",
    "    # Seleccionar el mejor modelo basado en MSE promedio\n",
    "    best_model = min(results, key=lambda x: x[2])  # x[2] es `cv_mean_mse`\n",
    "    print(\"\\nMejor modelo:\")\n",
    "    print(f\"- Alpha: {best_model[0]}\")\n",
    "    print(f\"- Fit Intercept: {best_model[1]}\")\n",
    "    print(f\"- MSE promedio (CV): {best_model[2]:.4f}\")\n",
    "    print(f\"- Desviación estándar del MSE (CV): {best_model[3]:.4f}\")\n",
    "    print(f\"- MAE (Conjunto de prueba): {best_model[6]['mae']:.4f}\")\n",
    "    print(f\"- R² (Conjunto de prueba): {best_model[6]['r2']:.4f}\")\n",
    "    print(f\"- RMSE (Conjunto de prueba): {best_model[6]['cv_rmse']:.4f}\")\n",
    "\n",
    "    # Guardar las métricas del mejor modelo\n",
    "    hyperparameters = {\"alpha\": best_model[0], \"fit_intercept\": best_model[1]}\n",
    "    save_best_model_metrics(best_model, \"RidgeRegression\", best_model[6], hyperparameters)\n",
    "\n",
    "    # Registrar el mejor modelo en WandB\n",
    "    wandb.log({\n",
    "        \"Mejor MSE promedio (CV)\": best_model[2],\n",
    "        \"Mejor Desviación estándar (CV)\": best_model[3],\n",
    "        \"Mejor RMSE (CV)\": best_model[6]['cv_rmse'],\n",
    "        \"Mejor MAE\": best_model[6]['mae'],\n",
    "        \"Mejor R²\": best_model[6]['r2']\n",
    "    })\n",
    "\n",
    "    '''\n",
    "    # Crear una tabla con los resultados numéricos del mejor modelo\n",
    "    table_data = [\n",
    "        [best_model[2],  # MSE promedio (CV)\n",
    "         best_model[3],  # Desviación estándar (CV)\n",
    "         best_model[6]['mae'],  # MAE\n",
    "         best_model[6]['r2'],  # R²\n",
    "         best_model[6]['cv_rmse']]  # RMSE\n",
    "    ]\n",
    "    table_columns = [\"MSE promedio (CV)\", \"Desviación estándar (CV)\", \"MAE\", \"R²\", \"RMSE\"]\n",
    "    wandb.log({\"Mejor Modelo\": wandb.Table(data=table_data, columns=table_columns)})\n",
    "    '''\n",
    "\n",
    "    # Finalizar el experimento en WandB\n",
    "    wandb.finish()\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Llamar a la función principal\n",
    "best_model_ridge = main_ridge(X_train, y_train, X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
