{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obligatorio - Machine Learning\n",
    "\n",
    "# 1. Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones principales\n",
    "import pandas as pd  # Manejo y análisis de datos estructurados (DataFrames)\n",
    "import numpy as np  # Operaciones numéricas y manejo de arrays\n",
    "import matplotlib.pyplot as plt  # Visualización de datos\n",
    "\n",
    "# Preprocesamiento y selección de características\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  # Codificación de variables categóricas y escalado de datos\n",
    "from sklearn.feature_selection import f_regression, SelectKBest  # Selección de características relevantes basadas en correlación\n",
    "\n",
    "# Modelos de aprendizaje supervisado\n",
    "from sklearn.linear_model import LinearRegression, Ridge  # Modelos lineales para regresión (Ridge incluye regularización)\n",
    "from sklearn.tree import DecisionTreeRegressor  # Árboles de decisión para regresión\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor  # Modelos avanzados: Random Forest, Gradient Boosting, AdaBoost\n",
    "from sklearn.neural_network import MLPRegressor  # Redes neuronales para regresión\n",
    "\n",
    "# Evaluación y optimización\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score  # Dividir datos, búsqueda de hiperparámetros y validación cruzada\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # Métricas de evaluación para modelos de regresión\n",
    "\n",
    "# Text Mining\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Representación numérica de texto (TF-IDF)\n",
    "\n",
    "# Utilidades estadísticas y preprocesamiento avanzado\n",
    "from scipy.stats.mstats import winsorize  # Manejo de valores extremos (outliers) mediante winsorización\n",
    "\n",
    "# Herramientas de pipeline\n",
    "from sklearn.pipeline import Pipeline  # Construcción de pipelines para flujos de preprocesamiento y modelado\n",
    "\n",
    "# Visualización adicional\n",
    "import matplotlib.pyplot as plt  # Gráficos adicionales para análisis visual\n",
    "\n",
    "# Weights and Biases\n",
    "import wandb  # Seguimiento, visualización y registro de métricas para experimentos de Machine Learning\n",
    "\n",
    "# Cargar datasets\n",
    "df_train = pd.read_csv('./dataset/train.csv')  # Cargar el conjunto de entrenamiento\n",
    "df_test = pd.read_csv('./dataset/test.csv')  # Cargar el conjunto de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Rellenar valores faltantes\n",
    "def clean_data(df):\n",
    "    # Completar valores faltantes\n",
    "    df['Year'] = df['Year'].fillna(df['Year'].median())  # Completar con la mediana\n",
    "    df['Publisher'] = df['Publisher'].fillna('Unknown')  # Completar con \"Unknown\"\n",
    "\n",
    "    # Eliminar columnas irrelevantes\n",
    "    if 'Summary' in df.columns:\n",
    "        df = df.drop(columns=['Summary'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Paso 2: Convertir columnas numéricas con valores inconsistentes\n",
    "def convert_to_numeric(value):\n",
    "    \"\"\"\n",
    "    Convierte valores como '1.2K' en valores numéricos.\n",
    "    \"\"\"\n",
    "    value_str = str(value)\n",
    "    if 'K' in value_str:\n",
    "        return float(value_str.replace('K', '')) * 1000\n",
    "    try:\n",
    "        return float(value_str)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "# Paso 3: Manejar outliers\n",
    "def handle_outliers(df, columns):\n",
    "    \"\"\"\n",
    "    Aplica winsorización para manejar valores extremos en las columnas especificadas.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = winsorize(df[col], limits=[0.01, 0.01])  # Recorta 1% inferior y superior\n",
    "    return df\n",
    "\n",
    "# Paso 4: Codificar variables categóricas\n",
    "def encode_categorical(df, categorical_columns):\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in categorical_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = label_encoder.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "# Paso 5: Escalar columnas numéricas\n",
    "def scale_numerical(df, numerical_columns):\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "    return df\n",
    "\n",
    "# Paso 6: Rellenar valores faltantes en `Genre` usando `Summary`\n",
    "def fill_missing_genres(df):\n",
    "    \"\"\"\n",
    "    Rellena los valores faltantes de la columna `Genre` basándose en la columna `Summary`.\n",
    "    Utiliza un modelo de clasificación de texto.\n",
    "    \"\"\"\n",
    "    # Separar filas con y sin `Genre`\n",
    "    df_with_genre = df[df['Genre'].notnull()]\n",
    "    df_missing_genre = df[df['Genre'].isnull()]\n",
    "\n",
    "    if len(df_missing_genre) > 0:\n",
    "        # Convertir valores categóricos de `Genre` a números\n",
    "        label_encoder = LabelEncoder()\n",
    "        df_with_genre['Genre'] = label_encoder.fit_transform(df_with_genre['Genre'])\n",
    "\n",
    "        # Modelo de clasificación de texto\n",
    "        text_clf = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english', max_features=1000)),\n",
    "            ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "        ])\n",
    "\n",
    "        # Entrenar el modelo con los datos disponibles\n",
    "        text_clf.fit(df_with_genre['Summary'], df_with_genre['Genre'])\n",
    "\n",
    "        # Predecir los géneros faltantes\n",
    "        predicted_genres = text_clf.predict(df_missing_genre['Summary'])\n",
    "\n",
    "        # Convertir las predicciones de vuelta a etiquetas originales\n",
    "        df_missing_genre['Genre'] = label_encoder.inverse_transform(predicted_genres)\n",
    "\n",
    "        # Combinar las filas con `Genre` y las predichas\n",
    "        df = pd.concat([df_with_genre, df_missing_genre])\n",
    "\n",
    "# Paso 7: Crear nuevas columnas derivadas\n",
    "def create_new_columns(df):\n",
    "    \"\"\"\n",
    "    Crea nuevas columnas derivadas basadas en la información existente.\n",
    "    \"\"\"\n",
    "    df['Game_Age'] = 2024 - df['Year']\n",
    "    \n",
    "    # Ratios regionales\n",
    "    df['NorthAmerica_Global_Ratio'] = df['North America'] / df['Global']\n",
    "    df['Europe_Global_Ratio'] = df['Europe'] / df['Global']\n",
    "    df['Japan_Global_Ratio'] = df['Japan'] / df['Global']\n",
    "    df['RestOfWorld_Global_Ratio'] = df['Rest of World'] / df['Global']\n",
    "\n",
    "    # Relación entre reseñas y wishlist\n",
    "    df['Reviews_Wishlist_Ratio'] = df['Number of Reviews'] / df['Wishlist']\n",
    "\n",
    "    # Interacciones categóricas\n",
    "    df['Publisher_Platform_Interaction'] = df['Publisher'] + df['Platform']\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_with_genre_and_columns(df):\n",
    "    # Limpiar datos\n",
    "    df = clean_data(df)\n",
    "\n",
    "    # Rellenar valores faltantes en `Genre` usando `Summary`\n",
    "    if 'Summary' in df.columns and 'Genre' in df.columns:\n",
    "        df = fill_missing_genres(df)\n",
    "\n",
    "    # Convertir columnas numéricas con valores inconsistentes\n",
    "    columns_to_convert = ['Europe', 'Japan', 'Rest of World', 'North America', \n",
    "                          'Global', 'Number of Reviews', 'Wishlist']\n",
    "    for col in columns_to_convert:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(convert_to_numeric)\n",
    "\n",
    "    # Manejar outliers\n",
    "    outlier_columns = ['Global', 'Wishlist']\n",
    "    df = handle_outliers(df, outlier_columns)\n",
    "\n",
    "    # Codificar columnas categóricas\n",
    "    categorical_columns = ['Game Title', 'Publisher', 'Platform', 'Genre']\n",
    "    df = encode_categorical(df, categorical_columns)\n",
    "\n",
    "    # Crear nuevas columnas derivadas\n",
    "    df = create_new_columns(df)\n",
    "\n",
    "    # Escalar columnas numéricas\n",
    "    numerical_columns = ['North America', 'Europe', 'Japan', 'Rest of World', \n",
    "                         'Global', 'Number of Reviews', 'Wishlist', 'Game_Age', \n",
    "                         'Europe_Global_Ratio', 'Japan_Global_Ratio', \n",
    "                         'NorthAmerica_Global_Ratio', 'RestOfWorld_Global_Ratio',\n",
    "                         'Reviews_Wishlist_Ratio']\n",
    "    df = scale_numerical(df, numerical_columns)\n",
    "\n",
    "    # Eliminar columnas irrelevantes\n",
    "    columns_to_drop = ['Game Title']\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "    # Eliminar las columnas regionales originales después de crear los ratios\n",
    "    columns_to_drop = ['North America', 'Europe', 'Japan', 'Rest of World']\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Aplicar el preprocesamiento actualizado\n",
    "df_train = preprocess_data_with_genre_and_columns(df_train)\n",
    "df_test = preprocess_data_with_genre_and_columns(df_test)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(\"Datos preprocesados con géneros rellenados y nuevas columnas (train):\")\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar correlación con la variable objetivo (para regresión)\n",
    "def evaluate_feature_correlation(X, y):\n",
    "    \"\"\"\n",
    "    Evalúa la correlación de cada característica con la variable objetivo.\n",
    "    Devuelve un DataFrame con las puntuaciones.\n",
    "    \"\"\"\n",
    "    selector = SelectKBest(score_func=f_regression, k='all')\n",
    "    selector.fit(X, y)\n",
    "    scores = selector.scores_\n",
    "\n",
    "    # Crear un DataFrame con las puntuaciones\n",
    "    feature_scores = pd.DataFrame({'Feature': X.columns, 'Score': scores})\n",
    "    feature_scores = feature_scores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "    print(\"Importancia de características basada en correlación:\")\n",
    "    print(feature_scores)\n",
    "    return feature_scores\n",
    "\n",
    "# Función para evaluar la importancia de características usando un modelo\n",
    "def evaluate_feature_importance_model(X, y):\n",
    "    \"\"\"\n",
    "    Evalúa la importancia de características utilizando un RandomForestRegressor.\n",
    "    Devuelve un DataFrame con las importancias.\n",
    "    \"\"\"\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X, y)\n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    # Crear un DataFrame con las importancias\n",
    "    feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "    feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Visualizar la importancia de características\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importances['Feature'], feature_importances['Importance'])\n",
    "    plt.xlabel(\"Importancia\")\n",
    "    plt.ylabel(\"Características\")\n",
    "    plt.title(\"Importancia de características según RandomForest\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Importancia de características basada en RandomForest:\")\n",
    "    print(feature_importances)\n",
    "    return feature_importances\n",
    "\n",
    "# Selección de las características más relevantes\n",
    "def select_top_features(X, y, k=10):\n",
    "    \"\"\"\n",
    "    Selecciona las k características más relevantes utilizando SelectKBest.\n",
    "    \"\"\"\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "    # Obtener las columnas seleccionadas\n",
    "    selected_columns = X.columns[selector.get_support()]\n",
    "    print(f\"Características seleccionadas ({k} mejores): {selected_columns}\")\n",
    "    return X_selected, selected_columns\n",
    "\n",
    "# Para df_train (como ya tienes)\n",
    "X_train = df_train.drop(columns=['Rating'])  # Variables predictoras\n",
    "y_train = df_train['Rating']  # Variable objetivo\n",
    "\n",
    "# Evaluar y seleccionar características en df_train\n",
    "correlation_scores = evaluate_feature_correlation(X_train, y_train)\n",
    "importance_scores = evaluate_feature_importance_model(X_train, y_train)\n",
    "X_train_selected, selected_columns = select_top_features(X_train, y_train, k=10)\n",
    "\n",
    "# Actualizar el dataset de entrenamiento\n",
    "df_train_selected = pd.DataFrame(X_train_selected, columns=selected_columns)\n",
    "df_train_selected['Rating'] = y_train  # Añadir la columna objetivo para usar en el modelo\n",
    "\n",
    "# Aplicar la misma selección de características al conjunto de prueba**\n",
    "if 'Rating' in df_test.columns:\n",
    "    X_test = df_test.drop(columns=['Rating'])  # Variables predictoras en el conjunto de prueba\n",
    "    y_test = df_test['Rating']  # Variable objetivo en el conjunto de prueba\n",
    "else:\n",
    "    X_test = df_test\n",
    "    y_test = None\n",
    "\n",
    "# Seleccionar las mismas características en df_test usando `selected_columns`\n",
    "X_test_selected = X_test[selected_columns]\n",
    "\n",
    "# Actualizar el dataset de prueba\n",
    "df_test_selected = pd.DataFrame(X_test_selected, columns=selected_columns)\n",
    "if y_test is not None:\n",
    "    df_test_selected['Rating'] = y_test  # Solo si `Rating` está disponible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceso de nuevo los datos eliminando columnas irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_optimized(df):\n",
    "\n",
    "    # Eliminar columnas menos relevantes\n",
    "    columns_to_drop = ['id', 'Publisher_Platform_Interaction', 'Publisher', 'Wishlist', \n",
    "                       'Number of Reviews', 'Reviews_Wishlist_Ratio']\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Aplicar el preprocesamiento optimizado\n",
    "df_train = preprocess_data_optimized(df_train)\n",
    "df_test = preprocess_data_optimized(df_test)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(\"Datos preprocesados optimizados (train):\")\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Función para evaluar correlación con la variable objetivo (para regresión)\n",
    "def evaluate_feature_correlation(X, y):\n",
    "    \"\"\"\n",
    "    Evalúa la correlación de cada característica con la variable objetivo.\n",
    "    Devuelve un DataFrame con las puntuaciones.\n",
    "    \"\"\"\n",
    "    selector = SelectKBest(score_func=f_regression, k='all')\n",
    "    selector.fit(X, y)\n",
    "    scores = selector.scores_\n",
    "\n",
    "    # Crear un DataFrame con las puntuaciones\n",
    "    feature_scores = pd.DataFrame({'Feature': X.columns, 'Score': scores})\n",
    "    feature_scores = feature_scores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "    print(\"Importancia de características basada en correlación:\")\n",
    "    print(feature_scores)\n",
    "    return feature_scores\n",
    "\n",
    "# Función para evaluar la importancia de características usando un modelo\n",
    "def evaluate_feature_importance_model(X, y):\n",
    "    \"\"\"\n",
    "    Evalúa la importancia de características utilizando un RandomForestRegressor.\n",
    "    Devuelve un DataFrame con las importancias.\n",
    "    \"\"\"\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X, y)\n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    # Crear un DataFrame con las importancias\n",
    "    feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "    feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Visualizar la importancia de características\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importances['Feature'], feature_importances['Importance'])\n",
    "    plt.xlabel(\"Importancia\")\n",
    "    plt.ylabel(\"Características\")\n",
    "    plt.title(\"Importancia de características según RandomForest\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Importancia de características basada en RandomForest:\")\n",
    "    print(feature_importances)\n",
    "    return feature_importances\n",
    "\n",
    "# Selección de las características más relevantes\n",
    "def select_top_features(X, y, k=10):\n",
    "    \"\"\"\n",
    "    Selecciona las k características más relevantes utilizando SelectKBest.\n",
    "    \"\"\"\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "    # Obtener las columnas seleccionadas\n",
    "    selected_columns = X.columns[selector.get_support()]\n",
    "    print(f\"Características seleccionadas ({k} mejores): {selected_columns}\")\n",
    "    return X_selected, selected_columns\n",
    "\n",
    "# Para df_train (como ya tienes)\n",
    "X_train = df_train.drop(columns=['Rating'])  # Variables predictoras\n",
    "y_train = df_train['Rating']  # Variable objetivo\n",
    "\n",
    "# Evaluar y seleccionar características en df_train\n",
    "correlation_scores = evaluate_feature_correlation(X_train, y_train)\n",
    "importance_scores = evaluate_feature_importance_model(X_train, y_train)\n",
    "X_train_selected, selected_columns = select_top_features(X_train, y_train, k=10)\n",
    "\n",
    "# Actualizar el dataset de entrenamiento\n",
    "df_train_selected = pd.DataFrame(X_train_selected, columns=selected_columns)\n",
    "df_train_selected['Rating'] = y_train  # Añadir la columna objetivo para usar en el modelo\n",
    "\n",
    "# Aplicar la misma selección de características al conjunto de prueba\n",
    "# Como no tiene la columna `Rating`, simplemente seleccionamos las columnas relevantes\n",
    "X_test = df_test[selected_columns]\n",
    "\n",
    "# Actualizar el dataset de prueba\n",
    "df_test_selected = pd.DataFrame(X_test, columns=selected_columns)\n",
    "\n",
    "# df_test_selected ahora contiene solo las características seleccionadas para hacer predicciones\n",
    "print(\"Características seleccionadas en el conjunto de prueba:\")\n",
    "print(df_test_selected.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y Evaluacion de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos para entrenamiento y prueba\n",
    "\n",
    "# Entrenamiento: X_train y y_train\n",
    "X_train = df_train_selected.drop(columns=['Rating'])  # Variables predictoras del conjunto de entrenamiento\n",
    "y_train = df_train_selected['Rating']  # Variable objetivo del conjunto de entrenamiento\n",
    "\n",
    "# Prueba: X_test (sin Rating)\n",
    "X_test = df_test_selected  # df_test seleccionado y procesado ya no incluye la columna Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar proyecto de Weights and Biases\n",
    "wandb.init(project=\"Obligatorio2024ML\", name=\"Evaluación_Regresión_Lineal\")\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Hiperparámetros para optimizar\n",
    "param_grid_lr = {\n",
    "    'fit_intercept': [True, False]  # Ajustar o no el intercepto\n",
    "}\n",
    "\n",
    "# Modelo base LinearRegression\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Optimización con GridSearchCV\n",
    "grid_search_lr = GridSearchCV(\n",
    "    estimator=lr_model,\n",
    "    param_grid=param_grid_lr,\n",
    "    cv=5,  # Validación cruzada con 5 particiones\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "grid_search_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_lr_model = grid_search_lr.best_estimator_\n",
    "print(\"Mejores parámetros para Regresión Lineal:\", grid_search_lr.best_params_)\n",
    "\n",
    "# Evaluación mediante validación cruzada en el conjunto de entrenamiento\n",
    "cv_scores = cross_val_score(best_lr_model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mean = -cv_scores.mean()  # MSE promedio (validación cruzada)\n",
    "cv_std = cv_scores.std()  # Desviación estándar del MSE\n",
    "cv_rmse = np.sqrt(cv_mean)  # RMSE promedio\n",
    "\n",
    "print(\"\\nValidación cruzada para Regresión Lineal:\")\n",
    "print(f\"Error Cuadrático Medio (MSE) promedio en validación cruzada: {cv_mean:.4f}\")\n",
    "print(f\"Raíz del Error Cuadrático Medio (RMSE) promedio en validación cruzada: {cv_rmse:.4f}\")\n",
    "print(f\"Desviación estándar del MSE en validación cruzada: {cv_std:.4f}\")\n",
    "\n",
    "# Generar predicciones para el conjunto de prueba\n",
    "y_pred = best_lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Guardar predicciones en un archivo CSV para evaluación externa\n",
    "predictions = pd.DataFrame({\n",
    "    \"Id\": range(len(y_pred)),  # Generar identificadores únicos para cada predicción\n",
    "    \"Predicted_Rating\": y_pred\n",
    "})\n",
    "predictions.to_csv(\"predicciones_regresion_lineal.csv\", index=False)\n",
    "print(\"Predicciones guardadas en 'predicciones_regresion_lineal.csv'.\")\n",
    "\n",
    "# Registrar las métricas de validación cruzada en WandB\n",
    "wandb.log({\n",
    "    \"Mejor Error Cuadrático Medio Negativo (CV)\": -grid_search_lr.best_score_,\n",
    "    \"MSE promedio en validación cruzada\": cv_mean,\n",
    "    \"RMSE promedio en validación cruzada\": cv_rmse,\n",
    "    \"Desviación estándar del MSE en validación cruzada\": cv_std\n",
    "})\n",
    "\n",
    "# Crear una tabla con los resultados de validación cruzada\n",
    "results_table = pd.DataFrame({\n",
    "    \"MSE promedio (CV)\": [cv_mean],\n",
    "    \"RMSE promedio (CV)\": [cv_rmse],\n",
    "    \"Desviación estándar (MSE)\": [cv_std]\n",
    "})\n",
    "\n",
    "# Registrar la tabla en WandB\n",
    "wandb.log({\"Tabla de Resultados (Validación Cruzada)\": wandb.Table(dataframe=results_table)})\n",
    "\n",
    "print(\"\\nResultados finales:\")\n",
    "print(results_table)\n",
    "\n",
    "# Finalizar WandB\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con regularizacion ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar proyecto de Weights and Biases\n",
    "wandb.init(project=\"Obligatorio2024ML\", name=\"Evaluación_Ridge_Regression\")\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Hiperparámetros para optimizar\n",
    "param_grid_ridge = {\n",
    "    'alpha': [0.1, 1, 10],  # Regularización L2\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "# Modelo base Ridge\n",
    "ridge_model = Ridge()\n",
    "\n",
    "# Optimización con GridSearchCV\n",
    "grid_search_ridge = GridSearchCV(\n",
    "    estimator=ridge_model,\n",
    "    param_grid=param_grid_ridge,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "grid_search_ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_ridge_model = grid_search_ridge.best_estimator_\n",
    "print(\"Mejores parámetros para Ridge Regression:\", grid_search_ridge.best_params_)\n",
    "\n",
    "# Validación cruzada\n",
    "cv_scores = cross_val_score(best_ridge_model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mean = -cv_scores.mean()\n",
    "cv_rmse = np.sqrt(cv_mean)\n",
    "cv_std = cv_scores.std()\n",
    "\n",
    "print(\"\\nValidación cruzada para Ridge Regression:\")\n",
    "print(f\"MSE promedio (CV): {cv_mean:.4f}\")\n",
    "print(f\"RMSE promedio (CV): {cv_rmse:.4f}\")\n",
    "print(f\"Desviación estándar (MSE): {cv_std:.4f}\")\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "y_pred = best_ridge_model.predict(X_test_scaled)\n",
    "y_pred_clipped = np.clip(y_pred, 6, 8.5)  # Asegurar que las predicciones estén en el rango esperado\n",
    "\n",
    "# Guardar predicciones\n",
    "predictions = pd.DataFrame({\n",
    "    \"Id\": range(len(y_pred_clipped)),\n",
    "    \"Predicted_Rating\": y_pred_clipped\n",
    "})\n",
    "predictions.to_csv(\"predicciones_ridge_regression.csv\", index=False)\n",
    "print(\"Predicciones guardadas en 'predicciones_ridge_regression.csv'.\")\n",
    "\n",
    "# Registrar métricas en WandB\n",
    "wandb.log({\n",
    "    \"Mejor MSE Negativo (CV)\": -grid_search_ridge.best_score_,\n",
    "    \"MSE promedio (CV)\": cv_mean,\n",
    "    \"RMSE promedio (CV)\": cv_rmse,\n",
    "    \"Desviación estándar (MSE)\": cv_std\n",
    "})\n",
    "\n",
    "# Crear una tabla con resultados\n",
    "results_table = pd.DataFrame({\n",
    "    \"MSE promedio (CV)\": [cv_mean],\n",
    "    \"RMSE promedio (CV)\": [cv_rmse],\n",
    "    \"Desviación estándar (MSE)\": [cv_std]\n",
    "})\n",
    "\n",
    "# Registrar la tabla en WandB\n",
    "wandb.log({\"Tabla de Resultados (Validación Cruzada)\": wandb.Table(dataframe=results_table)})\n",
    "\n",
    "# Finalizar WandB\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arboles de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar proyecto de Weights and Biases\n",
    "wandb.init(project=\"Obligatorio2024ML\", name=\"Evaluación_Árbol_Decisión\")\n",
    "\n",
    "# Hiperparámetros para optimizar\n",
    "param_grid_tree = {\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 10],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'max_leaf_nodes': [None, 10, 50, 100],\n",
    "    'min_impurity_decrease': [0.0, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Optimización con GridSearchCV\n",
    "grid_search_tree = GridSearchCV(\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    param_grid_tree,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "grid_search_tree.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_tree_model = grid_search_tree.best_estimator_\n",
    "print(\"Mejores parámetros para Árbol de Decisión:\", grid_search_tree.best_params_)\n",
    "\n",
    "# Validación cruzada para calcular métricas en el conjunto de entrenamiento\n",
    "cv_scores_mse = cross_val_score(best_tree_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mean_mse = -cv_scores_mse.mean()  # Promedio del MSE (negativo convertido a positivo)\n",
    "cv_std_mse = cv_scores_mse.std()  # Desviación estándar del MSE\n",
    "cv_rmse = np.sqrt(cv_mean_mse)  # RMSE promedio\n",
    "\n",
    "print(\"\\nValidación cruzada para Árbol de Decisión:\")\n",
    "print(f\"Error Cuadrático Medio (MSE) promedio en validación cruzada: {cv_mean_mse:.4f}\")\n",
    "print(f\"Raíz del Error Cuadrático Medio (RMSE) promedio en validación cruzada: {cv_rmse:.4f}\")\n",
    "print(f\"Desviación estándar del MSE en validación cruzada: {cv_std_mse:.4f}\")\n",
    "\n",
    "# Generar predicciones para el conjunto de prueba\n",
    "y_pred = best_tree_model.predict(X_test)\n",
    "\n",
    "# Guardar predicciones en un archivo CSV para evaluación externa\n",
    "predictions = pd.DataFrame({\n",
    "    \"Id\": range(len(y_pred)),  # Generar identificadores únicos para cada predicción\n",
    "    \"Predicted_Rating\": y_pred\n",
    "})\n",
    "predictions.to_csv(\"predicciones_arbol_decision.csv\", index=False)\n",
    "print(\"Predicciones guardadas en 'predicciones_arbol_decision.csv'.\")\n",
    "\n",
    "# Registrar las métricas de validación cruzada en WandB\n",
    "wandb.log({\n",
    "    \"Mejor Error Cuadrático Medio Negativo (CV)\": -grid_search_tree.best_score_,\n",
    "    \"MSE promedio en validación cruzada\": cv_mean_mse,\n",
    "    \"RMSE promedio en validación cruzada\": cv_rmse,\n",
    "    \"Desviación estándar del MSE en validación cruzada\": cv_std_mse\n",
    "})\n",
    "\n",
    "# Crear una tabla con los resultados de validación cruzada\n",
    "results_table = pd.DataFrame({\n",
    "    \"MSE promedio (CV)\": [cv_mean_mse],\n",
    "    \"RMSE promedio (CV)\": [cv_rmse],\n",
    "    \"Desviación estándar (MSE)\": [cv_std_mse]\n",
    "})\n",
    "\n",
    "# Registrar la tabla en WandB\n",
    "wandb.log({\"Tabla de Resultados (Validación Cruzada)\": wandb.Table(dataframe=results_table)})\n",
    "\n",
    "print(\"\\nResultados finales:\")\n",
    "print(results_table)\n",
    "\n",
    "# Finalizar WandB\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar proyecto de Weights and Biases\n",
    "wandb.init(project=\"Obligatorio2024ML\", name=\"Evaluación_Random_Forest\")\n",
    "\n",
    "# Hiperparámetros para optimizar\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1]\n",
    "}\n",
    "\n",
    "# Optimización con GridSearchCV\n",
    "grid_search_rf = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid_rf,\n",
    "    cv=5,  # Validación cruzada con 5 particiones\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Usa todos los núcleos disponibles\n",
    ")\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "optimized_rf_model = grid_search_rf.best_estimator_\n",
    "print(\"Mejores parámetros para Random Forest:\", grid_search_rf.best_params_)\n",
    "\n",
    "# Validación cruzada para calcular métricas en el conjunto de entrenamiento\n",
    "cv_scores_mse = cross_val_score(optimized_rf_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mean_mse = -cv_scores_mse.mean()  # Promedio del MSE (negativo convertido a positivo)\n",
    "cv_std_mse = cv_scores_mse.std()  # Desviación estándar del MSE\n",
    "cv_rmse = np.sqrt(cv_mean_mse)  # RMSE promedio\n",
    "\n",
    "print(\"\\nValidación cruzada para Random Forest:\")\n",
    "print(f\"Error Cuadrático Medio (MSE) promedio en validación cruzada: {cv_mean_mse:.4f}\")\n",
    "print(f\"Raíz del Error Cuadrático Medio (RMSE) promedio en validación cruzada: {cv_rmse:.4f}\")\n",
    "print(f\"Desviación estándar del MSE en validación cruzada: {cv_std_mse:.4f}\")\n",
    "\n",
    "# Generar predicciones para el conjunto de prueba\n",
    "y_pred = optimized_rf_model.predict(X_test)\n",
    "\n",
    "# Guardar predicciones en un archivo CSV para evaluación externa\n",
    "predictions = pd.DataFrame({\n",
    "    \"Id\": range(len(y_pred)),  # Generar identificadores únicos para cada predicción\n",
    "    \"Predicted_Rating\": y_pred\n",
    "})\n",
    "predictions.to_csv(\"predicciones_random_forest.csv\", index=False)\n",
    "print(\"Predicciones guardadas en 'predicciones_random_forest.csv'.\")\n",
    "\n",
    "# Registrar las métricas de validación cruzada en WandB\n",
    "wandb.log({\n",
    "    \"Mejor Error Cuadrático Medio Negativo (CV)\": -grid_search_rf.best_score_,\n",
    "    \"MSE promedio en validación cruzada\": cv_mean_mse,\n",
    "    \"RMSE promedio en validación cruzada\": cv_rmse,\n",
    "    \"Desviación estándar del MSE en validación cruzada\": cv_std_mse\n",
    "})\n",
    "\n",
    "# Crear una tabla con los resultados de validación cruzada\n",
    "results_table = pd.DataFrame({\n",
    "    \"MSE promedio (CV)\": [cv_mean_mse],\n",
    "    \"RMSE promedio (CV)\": [cv_rmse],\n",
    "    \"Desviación estándar (MSE)\": [cv_std_mse]\n",
    "})\n",
    "\n",
    "# Registrar la tabla en WandB\n",
    "wandb.log({\"Tabla de Resultados (Validación Cruzada)\": wandb.Table(dataframe=results_table)})\n",
    "\n",
    "print(\"\\nResultados finales:\")\n",
    "print(results_table)\n",
    "\n",
    "# Finalizar WandB\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar proyecto de Weights and Biases\n",
    "wandb.init(project=\"Obligatorio2024ML\", name=\"Evaluación_Gradient_Boosting\")\n",
    "\n",
    "# Hiperparámetros para optimizar\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0]  # Prueba con una fracción de los datos\n",
    "}\n",
    "\n",
    "# Optimización con GridSearchCV\n",
    "grid_search_gb = GridSearchCV(\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    param_grid_gb,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Usa todos los núcleos disponibles\n",
    ")\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_gb_model = grid_search_gb.best_estimator_\n",
    "print(\"Mejores parámetros para Gradient Boosting:\", grid_search_gb.best_params_)\n",
    "\n",
    "# Validación cruzada para calcular métricas en el conjunto de entrenamiento\n",
    "cv_scores_mse = cross_val_score(best_gb_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mean_mse = -cv_scores_mse.mean()  # MSE promedio (negativo convertido a positivo)\n",
    "cv_std_mse = cv_scores_mse.std()  # Desviación estándar del MSE\n",
    "cv_rmse = np.sqrt(cv_mean_mse)  # RMSE promedio\n",
    "\n",
    "print(\"\\nValidación cruzada para Gradient Boosting:\")\n",
    "print(f\"Error Cuadrático Medio (MSE) promedio en validación cruzada: {cv_mean_mse:.4f}\")\n",
    "print(f\"Raíz del Error Cuadrático Medio (RMSE) promedio en validación cruzada: {cv_rmse:.4f}\")\n",
    "print(f\"Desviación estándar del MSE en validación cruzada: {cv_std_mse:.4f}\")\n",
    "\n",
    "# Generar predicciones para el conjunto de prueba\n",
    "y_pred = best_gb_model.predict(X_test)\n",
    "\n",
    "# Guardar predicciones en un archivo CSV para evaluación externa\n",
    "predictions = pd.DataFrame({\n",
    "    \"Id\": range(len(y_pred)),  # Generar identificadores únicos para cada predicción\n",
    "    \"Predicted_Rating\": y_pred\n",
    "})\n",
    "predictions.to_csv(\"predicciones_gradient_boosting.csv\", index=False)\n",
    "print(\"Predicciones guardadas en 'predicciones_gradient_boosting.csv'.\")\n",
    "\n",
    "# Registrar las métricas de validación cruzada en WandB\n",
    "wandb.log({\n",
    "    \"Mejor Error Cuadrático Medio Negativo (CV)\": -grid_search_gb.best_score_,\n",
    "    \"MSE promedio en validación cruzada\": cv_mean_mse,\n",
    "    \"RMSE promedio en validación cruzada\": cv_rmse,\n",
    "    \"Desviación estándar del MSE en validación cruzada\": cv_std_mse\n",
    "})\n",
    "\n",
    "# Crear una tabla con los resultados de validación cruzada\n",
    "results_table = pd.DataFrame({\n",
    "    \"MSE promedio (CV)\": [cv_mean_mse],\n",
    "    \"RMSE promedio (CV)\": [cv_rmse],\n",
    "    \"Desviación estándar (MSE)\": [cv_std_mse]\n",
    "})\n",
    "\n",
    "# Registrar la tabla en WandB\n",
    "wandb.log({\"Tabla de Resultados (Validación Cruzada)\": wandb.Table(dataframe=results_table)})\n",
    "\n",
    "print(\"\\nResultados finales:\")\n",
    "print(results_table)\n",
    "\n",
    "# Finalizar WandB\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar proyecto de Weights and Biases\n",
    "wandb.init(project=\"Obligatorio2024ML\", name=\"Evaluación_AdaBoost\")\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Cambiar el estimador base a un árbol de decisión más profundo\n",
    "base_estimator = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Hiperparámetros para optimizar\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [100, 200, 300],  # Número de árboles en el modelo\n",
    "    'learning_rate': [0.01, 0.1],  # Tasa de aprendizaje\n",
    "    'estimator__max_depth': [5, 7, 10]  # Profundidad del estimador base\n",
    "}\n",
    "\n",
    "# Optimización con GridSearchCV\n",
    "grid_search_ada = GridSearchCV(\n",
    "    AdaBoostRegressor(estimator=base_estimator, random_state=42),\n",
    "    param_grid_ada,\n",
    "    cv=5,  # Validación cruzada\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Paralelización\n",
    ")\n",
    "\n",
    "# Entrenar el modelo con los datos escalados\n",
    "grid_search_ada.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_ada_model = grid_search_ada.best_estimator_\n",
    "print(\"Mejores parámetros para AdaBoost:\", grid_search_ada.best_params_)\n",
    "\n",
    "# Validación cruzada para calcular métricas en el conjunto de entrenamiento\n",
    "cv_scores_mse = cross_val_score(best_ada_model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mean_mse = -cv_scores_mse.mean()  # MSE promedio (validación cruzada, convertir a positivo)\n",
    "cv_std_mse = cv_scores_mse.std()  # Desviación estándar del MSE\n",
    "cv_rmse = np.sqrt(cv_mean_mse)  # RMSE promedio\n",
    "\n",
    "print(\"\\nValidación cruzada para AdaBoost:\")\n",
    "print(f\"Error Cuadrático Medio (MSE) promedio en validación cruzada: {cv_mean_mse:.4f}\")\n",
    "print(f\"Raíz del Error Cuadrático Medio (RMSE) promedio en validación cruzada: {cv_rmse:.4f}\")\n",
    "print(f\"Desviación estándar del MSE en validación cruzada: {cv_std_mse:.4f}\")\n",
    "\n",
    "# Generar predicciones para el conjunto de prueba\n",
    "y_pred = best_ada_model.predict(X_test_scaled)\n",
    "\n",
    "# Guardar predicciones en un archivo CSV para evaluación externa\n",
    "predictions = pd.DataFrame({\n",
    "    \"Id\": range(len(y_pred)),  # Generar identificadores únicos para cada predicción\n",
    "    \"Predicted_Rating\": y_pred\n",
    "})\n",
    "predictions.to_csv(\"predicciones_adaboost.csv\", index=False)\n",
    "print(\"Predicciones guardadas en 'predicciones_adaboost.csv'.\")\n",
    "\n",
    "# Registrar las métricas de validación cruzada en WandB\n",
    "wandb.log({\n",
    "    \"Mejor Error Cuadrático Medio Negativo (CV)\": -grid_search_ada.best_score_,\n",
    "    \"MSE promedio en validación cruzada\": cv_mean_mse,\n",
    "    \"RMSE promedio en validación cruzada\": cv_rmse,\n",
    "    \"Desviación estándar del MSE en validación cruzada\": cv_std_mse\n",
    "})\n",
    "\n",
    "# Crear una tabla con los resultados de validación cruzada\n",
    "results_table = pd.DataFrame({\n",
    "    \"MSE promedio (CV)\": [cv_mean_mse],\n",
    "    \"RMSE promedio (CV)\": [cv_rmse],\n",
    "    \"Desviación estándar (MSE)\": [cv_std_mse]\n",
    "})\n",
    "\n",
    "# Registrar la tabla en WandB\n",
    "wandb.log({\"Tabla de Resultados (Validación Cruzada)\": wandb.Table(dataframe=results_table)})\n",
    "\n",
    "print(\"\\nResultados finales:\")\n",
    "print(results_table)\n",
    "\n",
    "# Finalizar WandB\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar proyecto de Weights and Biases\n",
    "wandb.init(project=\"Obligatorio2024ML\", name=\"Evaluación_Redes_Neuronales\")\n",
    "\n",
    "# Escalar los datos (muy importante para redes neuronales)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Hiperparámetros inspirados en boosting\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(50, 50), (100, 50), (150, 100, 50)],  # Configuraciones de capas ocultas\n",
    "    'activation': ['relu'],  # Función de activación estándar para regresión\n",
    "    'solver': ['adam'],  # Algoritmo de optimización robusto\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # Regularización L2\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],  # Tasa de aprendizaje\n",
    "    'max_iter': [200],  # Número de iteraciones\n",
    "    'early_stopping': [True]  # Parada temprana\n",
    "}\n",
    "\n",
    "# Optimización con GridSearchCV\n",
    "grid_search_mlp = GridSearchCV(\n",
    "    MLPRegressor(random_state=42),\n",
    "    param_grid_mlp,\n",
    "    cv=5,  # Validación cruzada con 5 folds\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Paralelización\n",
    ")\n",
    "\n",
    "# Entrenar el modelo con los datos escalados\n",
    "grid_search_mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_mlp_model = grid_search_mlp.best_estimator_\n",
    "print(\"Mejores parámetros para Redes Neuronales:\", grid_search_mlp.best_params_)\n",
    "\n",
    "# Validación cruzada en el conjunto de entrenamiento\n",
    "cv_scores_mse = cross_val_score(best_mlp_model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mean_mse = -cv_scores_mse.mean()  # MSE promedio (convertido a positivo)\n",
    "cv_std_mse = cv_scores_mse.std()  # Desviación estándar del MSE\n",
    "cv_rmse = np.sqrt(cv_mean_mse)  # RMSE promedio\n",
    "\n",
    "print(\"\\nValidación cruzada para Redes Neuronales:\")\n",
    "print(f\"Error Cuadrático Medio (MSE) promedio en validación cruzada: {cv_mean_mse:.4f}\")\n",
    "print(f\"Raíz del Error Cuadrático Medio (RMSE) promedio en validación cruzada: {cv_rmse:.4f}\")\n",
    "print(f\"Desviación estándar del MSE en validación cruzada: {cv_std_mse:.4f}\")\n",
    "\n",
    "# Generar predicciones para el conjunto de prueba\n",
    "y_pred = best_mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Guardar predicciones en un archivo CSV para evaluación externa\n",
    "predictions = pd.DataFrame({\n",
    "    \"Id\": range(len(y_pred)),  # Generar identificadores únicos para cada predicción\n",
    "    \"Predicted_Rating\": y_pred\n",
    "})\n",
    "predictions.to_csv(\"predicciones_redes_neuronales.csv\", index=False)\n",
    "print(\"Predicciones guardadas en 'predicciones_redes_neuronales.csv'.\")\n",
    "\n",
    "# Registrar las métricas en WandB\n",
    "wandb.log({\n",
    "    \"Mejor Error Cuadrático Medio Negativo (CV)\": -grid_search_mlp.best_score_,\n",
    "    \"MSE promedio en validación cruzada\": cv_mean_mse,\n",
    "    \"RMSE promedio en validación cruzada\": cv_rmse,\n",
    "    \"Desviación estándar del MSE en validación cruzada\": cv_std_mse\n",
    "})\n",
    "\n",
    "# Crear una tabla con los resultados de validación cruzada\n",
    "results_table = pd.DataFrame({\n",
    "    \"MSE promedio (CV)\": [cv_mean_mse],\n",
    "    \"RMSE promedio (CV)\": [cv_rmse],\n",
    "    \"Desviación estándar (MSE)\": [cv_std_mse]\n",
    "})\n",
    "\n",
    "# Registrar la tabla en WandB\n",
    "wandb.log({\"Tabla de Resultados (Validación Cruzada)\": wandb.Table(dataframe=results_table)})\n",
    "\n",
    "print(\"\\nResultados finales:\")\n",
    "print(results_table)\n",
    "\n",
    "# Finalizar WandB\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportacion de predicciones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
